{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jxPMeugQ0okg"
   },
   "source": [
    "## BERT as a service\n",
    "\n",
    "This notebook demonstrates how to build a complete machine learning pipeline using TensorFlow Extended ([TFX](https://www.tensorflow.org/tfx)) to serve a BERT model for text sentiment classification.\n",
    "\n",
    "Notes:\n",
    " - Data: IMDB Movie Reviews (5000 samples) [original source](https://ai.stanford.edu/~amaas/data/sentiment/)\n",
    " - Model: BERT base uncased (english) from [HuggingFace](https://huggingface.co/bert-base-uncased)\n",
    " - Processor: BERT uncased (english seq_length=128) from [TF HUB](https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3)\n",
    "\n",
    "\n",
    "You can check references, additional information, and resources at the [GitHub repository](https://github.com/dimitreOliveira/bert-as-a-service_TFX)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-am1yWXt0okh"
   },
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "XNiqq_kN0okj"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pip in /opt/conda/lib/python3.7/site-packages (21.1.2)\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "tensorflow-io 0.18.0 requires tensorflow-io-gcs-filesystem==0.18.0, which is not installed.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# Use the latest version of pip.\n",
    "!pip install --upgrade pip\n",
    "# Install tfx and kfp Python packages.\n",
    "!pip install -q --upgrade tfx[kfp]==1.0.0rc1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hX1rqpbQ0okp"
   },
   "source": [
    "### Import packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "id": "XAIoKMNG0okq"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import urllib\n",
    "import tfx\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow version: 2.5.0\n",
      "TFX version: 1.0.0-rc1\n"
     ]
    }
   ],
   "source": [
    "print(f'TensorFlow version: {tf.__version__}')\n",
    "print(f'TFX version: {tfx.__version__}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_7JLpaXT0okv"
   },
   "source": [
    "[Kubeflow Pipelines](https://www.kubeflow.org/docs/pipelines/overview/pipelines-overview/) environment variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "Hw3nsooU0okv"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: GOOGLE_CLOUD_PROJECT=gcp-bert-aas\n",
      "GCP project ID:gcp-bert-aas\n"
     ]
    }
   ],
   "source": [
    "# Read GCP project id from env.\n",
    "shell_output=!gcloud config list --format 'value(core.project)' 2>/dev/null\n",
    "GOOGLE_CLOUD_PROJECT=shell_output[0]\n",
    "%env GOOGLE_CLOUD_PROJECT={GOOGLE_CLOUD_PROJECT}\n",
    "print(\"GCP project ID:\" + GOOGLE_CLOUD_PROJECT)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "A_6r4uzE0oky"
   },
   "source": [
    "KFP endpoint\n",
    "\"AI Platform > Pipeline > pipeline instance `settings`\"\n",
    "**ENDPOINT should contain only the hostname part of the URL.** For example, if the URL of the KFP dashboard is `https://1e9deb537390ca22-dot-asia-east1.pipelines.googleusercontent.com/#/start`, ENDPOINT value becomes `1e9deb537390ca22-dot-asia-east1.pipelines.googleusercontent.com`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "AzqEQORV0oky"
   },
   "outputs": [],
   "source": [
    "# This refers to the KFP cluster endpoint\n",
    "ENDPOINT='4c4887d40ceb4e53-dot-us-central1.pipelines.googleusercontent.com'\n",
    "if not ENDPOINT:\n",
    "    from absl import logging\n",
    "    logging.error('Set your ENDPOINT in this cell.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "K6T-KXeA0ok3"
   },
   "source": [
    "Set the image name as `tfx-pipeline` under the current GCP project."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "3ztxXOVD0ok4"
   },
   "outputs": [],
   "source": [
    "# Docker image name for the pipeline image.\n",
    "CUSTOM_TFX_IMAGE='gcr.io/' + GOOGLE_CLOUD_PROJECT + '/tfx-pipeline'\n",
    "print(CUSTOM_TFX_IMAGE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "cIPlt-700ok-"
   },
   "outputs": [],
   "source": [
    "PIPELINE_NAME=\"my_pipeline\"\n",
    "PROJECT_DIR=os.path.join(os.path.expanduser(\"~\"), \"imported\", PIPELINE_NAME)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yxOT19QS0olH"
   },
   "source": [
    "Change the working directory context in this notebook to the project directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "6P-HljcU0olI"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/jupyter/imported/my_pipeline\n"
     ]
    }
   ],
   "source": [
    "%cd {PROJECT_DIR}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IzT2PFrN0olQ"
   },
   "source": [
    "## Source files\n",
    "\n",
    "Here is brief introduction to each of the Python files.\n",
    "-   `data` - This directory contains the datasets.\n",
    "-   `models` - This directory contains ML model definitions.\n",
    "    -   `bert_aas_utils.py` — defines utility functions for the pipeline\n",
    "-   `pipeline` - This directory contains the definition of the pipeline\n",
    "    -   `configs.py` — defines common constants for pipeline runners\n",
    "    -   `pipeline.py` — defines TFX components and a pipeline\n",
    "-   `local_runner.py`, `kubeflow_runner.py` — define runners for each orchestration engine\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Download data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('data/IMDB_dataset.csv', <http.client.HTTPMessage at 0x7fb759992a10>)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_csv_url = 'https://raw.githubusercontent.com/dimitreOliveira/bert-as-a-service_TFX/main/Data/IMDB_5k_dataset.csv'\n",
    "data_csv_filename = 'IMDB_dataset.csv'\n",
    "\n",
    "_data_dir = 'data/'\n",
    "if not os.path.exists(_data_dir):\n",
    "    os.makedirs(_data_dir)\n",
    "\n",
    "# Download data\n",
    "urllib.request.urlretrieve(data_csv_url, f'{_data_dir}{data_csv_filename}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Upload our sample data to GCS bucket so that we can use it in our pipeline later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "id": "gW-dSHW-TSdc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Copying file://data/IMDB_dataset.csv [Content-Type=text/csv]...\n",
      "/ [1 files][  6.3 MiB/  6.3 MiB]                                                \n",
      "Operation completed over 1 objects/6.3 MiB.                                      \n"
     ]
    }
   ],
   "source": [
    "!gsutil cp data/IMDB_dataset.csv gs://{GOOGLE_CLOUD_PROJECT}-kubeflowpipelines-default/bert-aas/data/IMDB_dataset.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wc54hDZu0ole"
   },
   "source": [
    "## Create TFX pipeline\n",
    "\n",
    "Components in the TFX pipeline will generate outputs for each run as [ML Metadata Artifacts](https://www.tensorflow.org/tfx/guide/mlmd), and they need to be stored somewhere. You can use any storage which the KFP cluster can access, and for this example we will use Google Cloud Storage (GCS). A default GCS bucket should have been created automatically. Its name will be `<your-project-id>-kubeflowpipelines-default`.\n",
    "\n",
    "Let's create a TFX pipeline using the `tfx pipeline create` command.\n",
    "\n",
    ">Note: When creating a pipeline for KFP, we need a container image which will be used to run our pipeline. And `skaffold` will build the image for us. Because skaffold pulls base images from the docker hub, it will take 5~10 minutes when we build the image for the first time, but it will take much less time from the second build."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "kOU7zQof0olf"
   },
   "outputs": [],
   "source": [
    "!tfx pipeline create  \\\n",
    "--pipeline-path=kubeflow_runner.py \\\n",
    "--endpoint={ENDPOINT} \\\n",
    "--build-image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QmA6___Y0olh"
   },
   "source": [
    "While creating a pipeline, `Dockerfile` will be generated to build a Docker image. Don't forget to add it to the source control system (for example, git) along with other source files.\n",
    "\n",
    "NOTE: `kubeflow` will be automatically selected as an orchestration engine if `airflow` is not installed and `--engine` is not specified."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "cKSjVVsa0oli"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-06-05 14:39:12.884349: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0\n",
      "WARNING:absl:RuntimeParameter is only supported on Cloud-based DAG runner currently.\n",
      "CLI\n",
      "Creating a run for pipeline: my_pipeline\n",
      "Detected Kubeflow.\n",
      "Use --engine flag if you intend to use a different orchestrator.\n",
      "/opt/conda/lib/python3.7/site-packages/kfp/_client.py:182: UserWarning: The host 4c4887d40ceb4e53-dot-us-central1.pipelines.googleusercontent.com does not contain the \"http\" or \"https\" protocol. Defaults to \"https\".\n",
      "  ' Defaults to \"https\".' % host)\n",
      "Run created for pipeline: my_pipeline\n",
      "+===============+======================================+========+===========================+=============================================================================================================================+\n",
      "| pipeline_name | run_id                               | status | created_at                | link                                                                                                                        |\n",
      "+===============+======================================+========+===========================+=============================================================================================================================+\n",
      "| my_pipeline   | 6120e861-4c84-4fb1-8b9e-8ffe2f52e860 | None   | 2021-06-05T14:39:30+00:00 | http://4c4887d40ceb4e53-dot-us-central1.pipelines.googleusercontent.com/#/runs/details/6120e861-4c84-4fb1-8b9e-8ffe2f52e860 |\n",
      "+===============+======================================+========+===========================+=============================================================================================================================+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!tfx run create  \\\n",
    "--pipeline-name={PIPELINE_NAME} \\\n",
    "--endpoint={ENDPOINT}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Pg0VxvUC0olk"
   },
   "source": [
    "Or, you can also run the pipeline in the KFP Dashboard.  The new execution run will be listed under Experiments in the KFP Dashboard.  Clicking into the experiment will allow you to monitor progress and visualize the artifacts created during the execution run."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nLN4ges90oll"
   },
   "source": [
    "However, we recommend visiting the KFP Dashboard. You can access the KFP Dashboard from the Cloud AI Platform Pipelines menu in Google Cloud Console. Once you visit the dashboard, you will be able to find the pipeline, and access a wealth of information about the pipeline.\n",
    "For example, you can find your runs under the *Experiments* menu, and when you open your execution run under Experiments you can find all your artifacts from the pipeline under *Artifacts* menu.\n",
    "\n",
    ">Note: If your pipeline run fails, you can see detailed logs for each TFX component in the Experiments tab in the KFP Dashboard.\n",
    "    \n",
    "One of the major sources of failure is permission related problems. Please make sure your KFP cluster has permissions to access Google Cloud APIs. This can be configured [when you create a KFP cluster in GCP](https://cloud.google.com/ai-platform/pipelines/docs/setting-up), or see [Troubleshooting document in GCP](https://cloud.google.com/ai-platform/pipelines/docs/troubleshooting)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### In case the TFX pipeline needs to be updated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "id": "VE-Pqvto0olm"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-06-05 20:42:00.534710: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0\n",
      "WARNING:absl:RuntimeParameter is only supported on Cloud-based DAG runner currently.\n",
      "CLI\n",
      "Updating pipeline\n",
      "Detected Kubeflow.\n",
      "Use --engine flag if you intend to use a different orchestrator.\n",
      "/opt/conda/lib/python3.7/site-packages/kfp/_client.py:182: UserWarning: The host 4c4887d40ceb4e53-dot-us-central1.pipelines.googleusercontent.com does not contain the \"http\" or \"https\" protocol. Defaults to \"https\".\n",
      "  ' Defaults to \"https\".' % host)\n",
      "INFO:absl:Excluding no splits because exclude_splits is not set.\n",
      "INFO:absl:Excluding no splits because exclude_splits is not set.\n",
      "INFO:absl:Excluding no splits because exclude_splits is not set.\n",
      "[Docker] Step 1/4 : FROM tensorflow/tfx:1.0.0-rc1[Docker] \n",
      "[Docker] The push refers to repository [gcr.io/gcp-bert-aas/my_pipeline]\n",
      "[Docker] Preparing\n",
      "[Docker] Preparing\n",
      "[Docker] Preparing\n",
      "[Docker] Preparing\n",
      "[Docker] Preparing\n",
      "[Docker] Preparing\n",
      "[Docker] Preparing\n",
      "[Docker] Preparing\n",
      "[Docker] Preparing\n",
      "[Docker] Preparing\n",
      "[Docker] Preparing\n",
      "[Docker] Preparing\n",
      "[Docker] Preparing\n",
      "[Docker] Preparing\n",
      "[Docker] Preparing\n",
      "[Docker] Preparing\n",
      "[Docker] Preparing\n",
      "[Docker] Preparing\n",
      "[Docker] Preparing\n",
      "[Docker] Preparing\n",
      "[Docker] Preparing\n",
      "[Docker] Preparing\n",
      "[Docker] Preparing\n",
      "[Docker] Preparing\n",
      "[Docker] Preparing\n",
      "[Docker] Preparing\n",
      "[Docker] Preparing\n",
      "[Docker] Preparing\n",
      "[Docker] Preparing\n",
      "[Docker] Preparing\n",
      "[Docker] Preparing\n",
      "[Docker] Preparing\n",
      "[Docker] Preparing\n",
      "[Docker] Preparing\n",
      "[Docker] Preparing\n",
      "[Docker] Preparing\n",
      "[Docker] Preparing\n",
      "[Docker] Preparing\n",
      "[Docker] Preparing\n",
      "[Docker] Preparing\n",
      "[Docker] Preparing\n",
      "[Docker] Waiting\n",
      "[Docker] Waiting\n",
      "[Docker] Waiting\n",
      "[Docker] Waiting\n",
      "[Docker] Waiting\n",
      "[Docker] Waiting\n",
      "[Docker] Waiting\n",
      "[Docker] Waiting\n",
      "[Docker] Waiting\n",
      "[Docker] Waiting\n",
      "[Docker] Waiting\n",
      "[Docker] Waiting\n",
      "[Docker] Waiting\n",
      "[Docker] Waiting\n",
      "[Docker] Waiting\n",
      "[Docker] Waiting\n",
      "[Docker] Waiting\n",
      "[Docker] Waiting\n",
      "[Docker] Waiting\n",
      "[Docker] Waiting\n",
      "[Docker] Waiting\n",
      "[Docker] Waiting\n",
      "[Docker] Waiting\n",
      "[Docker] Waiting\n",
      "[Docker] Waiting\n",
      "[Docker] Waiting\n",
      "[Docker] Waiting\n",
      "[Docker] Waiting\n",
      "[Docker] Waiting\n",
      "[Docker] Waiting\n",
      "[Docker] Waiting\n",
      "[Docker] Waiting\n",
      "[Docker] Waiting\n",
      "[Docker] Waiting\n",
      "[Docker] Waiting\n",
      "[Docker] Waiting\n",
      "[Docker] Layer already exists\n",
      "[Docker] Layer already exists\n",
      "[Docker] Layer already exists\n",
      "[Docker] Layer already exists\n",
      "[Docker] Layer already exists\n",
      "[Docker] Layer already exists\n",
      "[Docker] Layer already exists\n",
      "[Docker] Layer already exists\n",
      "[Docker] Layer already exists\n",
      "[Docker] Layer already exists\n",
      "[Docker] Layer already exists\n",
      "[Docker] Layer already exists\n",
      "[Docker] Layer already exists\n",
      "[Docker] Layer already exists\n",
      "[Docker] Layer already exists\n",
      "[Docker] Layer already exists\n",
      "[Docker] Layer already exists\n",
      "[Docker] Layer already exists\n",
      "[Docker] Layer already exists\n",
      "[Docker] Layer already exists\n",
      "[Docker] Layer already exists\n",
      "[Docker] Layer already exists\n",
      "[Docker] Layer already exists\n",
      "[Docker] Layer already exists\n",
      "[Docker] Layer already exists\n",
      "[Docker] Layer already exists\n",
      "[Docker] Layer already exists\n",
      "[Docker] Layer already exists\n",
      "[Docker] Layer already exists\n",
      "[Docker] Layer already exists\n",
      "[Docker] Layer already exists\n",
      "[Docker] Layer already exists\n",
      "[Docker] Layer already exists\n",
      "[Docker] Layer already exists\n",
      "[Docker] Layer already exists\n",
      "[Docker] Layer already exists\n",
      "[Docker] Layer already exists\n",
      "[Docker] Layer already exists\n",
      "[Docker] Layer already exists\n",
      "[Docker] Layer already exists\n",
      "[Docker] Layer already exists\n",
      "[Docker] latest: digest: sha256:90f7fc8409011a44175469fea31608e165d63c67cfd7e97562b3c2ffa9339bdf size: 8926\n",
      "New container image \"gcr.io/gcp-bert-aas/my_pipeline@sha256:90f7fc8409011a44175469fea31608e165d63c67cfd7e97562b3c2ffa9339bdf\" was built.\n",
      "INFO:absl:Generating ephemeral wheel package for '/home/jupyter/imported/my_pipeline/pipeline/transform_utils.py' (including modules: ['configs', 'pipeline', 'train_utils', 'transform_utils']).\n",
      "INFO:absl:User module package has hash fingerprint version 3d7dd251b0135438273f0ff7986ed6d732f18a1f0e073c57521aa6ae14a214a5.\n",
      "INFO:absl:Executing: ['/opt/conda/bin/python3.7', '/tmp/tmp3xauoyi7/_tfx_generated_setup.py', 'bdist_wheel', '--bdist-dir', '/tmp/tmp7zbggorl', '--dist-dir', '/tmp/tmpoaw07g9p']\n",
      "running bdist_wheel\n",
      "running build\n",
      "running build_py\n",
      "creating build\n",
      "creating build/lib\n",
      "copying configs.py -> build/lib\n",
      "copying pipeline.py -> build/lib\n",
      "copying train_utils.py -> build/lib\n",
      "copying transform_utils.py -> build/lib\n",
      "installing to /tmp/tmp7zbggorl\n",
      "running install\n",
      "running install_lib\n",
      "copying build/lib/configs.py -> /tmp/tmp7zbggorl\n",
      "copying build/lib/pipeline.py -> /tmp/tmp7zbggorl\n",
      "copying build/lib/train_utils.py -> /tmp/tmp7zbggorl\n",
      "copying build/lib/transform_utils.py -> /tmp/tmp7zbggorl\n",
      "running install_egg_info\n",
      "running egg_info\n",
      "creating tfx_user_code_Transform.egg-info\n",
      "writing tfx_user_code_Transform.egg-info/PKG-INFO\n",
      "writing dependency_links to tfx_user_code_Transform.egg-info/dependency_links.txt\n",
      "writing top-level names to tfx_user_code_Transform.egg-info/top_level.txt\n",
      "writing manifest file 'tfx_user_code_Transform.egg-info/SOURCES.txt'\n",
      "reading manifest file 'tfx_user_code_Transform.egg-info/SOURCES.txt'\n",
      "writing manifest file 'tfx_user_code_Transform.egg-info/SOURCES.txt'\n",
      "Copying tfx_user_code_Transform.egg-info to /tmp/tmp7zbggorl/tfx_user_code_Transform-0.0+3d7dd251b0135438273f0ff7986ed6d732f18a1f0e073c57521aa6ae14a214a5-py3.7.egg-info\n",
      "running install_scripts\n",
      "creating /tmp/tmp7zbggorl/tfx_user_code_Transform-0.0+3d7dd251b0135438273f0ff7986ed6d732f18a1f0e073c57521aa6ae14a214a5.dist-info/WHEEL\n",
      "creating '/tmp/tmpoaw07g9p/tfx_user_code_Transform-0.0+3d7dd251b0135438273f0ff7986ed6d732f18a1f0e073c57521aa6ae14a214a5-py3-none-any.whl' and adding '/tmp/tmp7zbggorl' to it\n",
      "adding 'configs.py'\n",
      "adding 'pipeline.py'\n",
      "adding 'train_utils.py'\n",
      "adding 'transform_utils.py'\n",
      "adding 'tfx_user_code_Transform-0.0+3d7dd251b0135438273f0ff7986ed6d732f18a1f0e073c57521aa6ae14a214a5.dist-info/METADATA'\n",
      "adding 'tfx_user_code_Transform-0.0+3d7dd251b0135438273f0ff7986ed6d732f18a1f0e073c57521aa6ae14a214a5.dist-info/WHEEL'\n",
      "adding 'tfx_user_code_Transform-0.0+3d7dd251b0135438273f0ff7986ed6d732f18a1f0e073c57521aa6ae14a214a5.dist-info/top_level.txt'\n",
      "adding 'tfx_user_code_Transform-0.0+3d7dd251b0135438273f0ff7986ed6d732f18a1f0e073c57521aa6ae14a214a5.dist-info/RECORD'\n",
      "removing /tmp/tmp7zbggorl\n",
      "INFO:absl:Successfully built user code wheel distribution at 'gs://gcp-bert-aas-kubeflowpipelines-default/tfx_pipeline_output/my_pipeline/_wheels/tfx_user_code_Transform-0.0+3d7dd251b0135438273f0ff7986ed6d732f18a1f0e073c57521aa6ae14a214a5-py3-none-any.whl'; target user module is 'transform_utils'.\n",
      "INFO:absl:Full user module path is 'transform_utils@gs://gcp-bert-aas-kubeflowpipelines-default/tfx_pipeline_output/my_pipeline/_wheels/tfx_user_code_Transform-0.0+3d7dd251b0135438273f0ff7986ed6d732f18a1f0e073c57521aa6ae14a214a5-py3-none-any.whl'\n",
      "INFO:absl:Generating ephemeral wheel package for '/home/jupyter/imported/my_pipeline/pipeline/train_utils.py' (including modules: ['configs', 'pipeline', 'train_utils', 'transform_utils']).\n",
      "INFO:absl:User module package has hash fingerprint version 3d7dd251b0135438273f0ff7986ed6d732f18a1f0e073c57521aa6ae14a214a5.\n",
      "INFO:absl:Executing: ['/opt/conda/bin/python3.7', '/tmp/tmpkk0u3r8p/_tfx_generated_setup.py', 'bdist_wheel', '--bdist-dir', '/tmp/tmpbj2grh1p', '--dist-dir', '/tmp/tmp5w179yxx']\n",
      "running bdist_wheel\n",
      "running build\n",
      "running build_py\n",
      "creating build\n",
      "creating build/lib\n",
      "copying configs.py -> build/lib\n",
      "copying pipeline.py -> build/lib\n",
      "copying train_utils.py -> build/lib\n",
      "copying transform_utils.py -> build/lib\n",
      "installing to /tmp/tmpbj2grh1p\n",
      "running install\n",
      "running install_lib\n",
      "copying build/lib/configs.py -> /tmp/tmpbj2grh1p\n",
      "copying build/lib/pipeline.py -> /tmp/tmpbj2grh1p\n",
      "copying build/lib/train_utils.py -> /tmp/tmpbj2grh1p\n",
      "copying build/lib/transform_utils.py -> /tmp/tmpbj2grh1p\n",
      "running install_egg_info\n",
      "running egg_info\n",
      "creating tfx_user_code_Tuner.egg-info\n",
      "writing tfx_user_code_Tuner.egg-info/PKG-INFO\n",
      "writing dependency_links to tfx_user_code_Tuner.egg-info/dependency_links.txt\n",
      "writing top-level names to tfx_user_code_Tuner.egg-info/top_level.txt\n",
      "writing manifest file 'tfx_user_code_Tuner.egg-info/SOURCES.txt'\n",
      "reading manifest file 'tfx_user_code_Tuner.egg-info/SOURCES.txt'\n",
      "writing manifest file 'tfx_user_code_Tuner.egg-info/SOURCES.txt'\n",
      "Copying tfx_user_code_Tuner.egg-info to /tmp/tmpbj2grh1p/tfx_user_code_Tuner-0.0+3d7dd251b0135438273f0ff7986ed6d732f18a1f0e073c57521aa6ae14a214a5-py3.7.egg-info\n",
      "running install_scripts\n",
      "creating /tmp/tmpbj2grh1p/tfx_user_code_Tuner-0.0+3d7dd251b0135438273f0ff7986ed6d732f18a1f0e073c57521aa6ae14a214a5.dist-info/WHEEL\n",
      "creating '/tmp/tmp5w179yxx/tfx_user_code_Tuner-0.0+3d7dd251b0135438273f0ff7986ed6d732f18a1f0e073c57521aa6ae14a214a5-py3-none-any.whl' and adding '/tmp/tmpbj2grh1p' to it\n",
      "adding 'configs.py'\n",
      "adding 'pipeline.py'\n",
      "adding 'train_utils.py'\n",
      "adding 'transform_utils.py'\n",
      "adding 'tfx_user_code_Tuner-0.0+3d7dd251b0135438273f0ff7986ed6d732f18a1f0e073c57521aa6ae14a214a5.dist-info/METADATA'\n",
      "adding 'tfx_user_code_Tuner-0.0+3d7dd251b0135438273f0ff7986ed6d732f18a1f0e073c57521aa6ae14a214a5.dist-info/WHEEL'\n",
      "adding 'tfx_user_code_Tuner-0.0+3d7dd251b0135438273f0ff7986ed6d732f18a1f0e073c57521aa6ae14a214a5.dist-info/top_level.txt'\n",
      "adding 'tfx_user_code_Tuner-0.0+3d7dd251b0135438273f0ff7986ed6d732f18a1f0e073c57521aa6ae14a214a5.dist-info/RECORD'\n",
      "removing /tmp/tmpbj2grh1p\n",
      "INFO:absl:Successfully built user code wheel distribution at 'gs://gcp-bert-aas-kubeflowpipelines-default/tfx_pipeline_output/my_pipeline/_wheels/tfx_user_code_Tuner-0.0+3d7dd251b0135438273f0ff7986ed6d732f18a1f0e073c57521aa6ae14a214a5-py3-none-any.whl'; target user module is 'train_utils'.\n",
      "INFO:absl:Full user module path is 'train_utils@gs://gcp-bert-aas-kubeflowpipelines-default/tfx_pipeline_output/my_pipeline/_wheels/tfx_user_code_Tuner-0.0+3d7dd251b0135438273f0ff7986ed6d732f18a1f0e073c57521aa6ae14a214a5-py3-none-any.whl'\n",
      "INFO:absl:Generating ephemeral wheel package for '/home/jupyter/imported/my_pipeline/pipeline/train_utils.py' (including modules: ['configs', 'pipeline', 'train_utils', 'transform_utils']).\n",
      "INFO:absl:User module package has hash fingerprint version 3d7dd251b0135438273f0ff7986ed6d732f18a1f0e073c57521aa6ae14a214a5.\n",
      "INFO:absl:Executing: ['/opt/conda/bin/python3.7', '/tmp/tmpm0l4kpj8/_tfx_generated_setup.py', 'bdist_wheel', '--bdist-dir', '/tmp/tmprjs10nqd', '--dist-dir', '/tmp/tmpwfmzlfwx']\n",
      "running bdist_wheel\n",
      "running build\n",
      "running build_py\n",
      "creating build\n",
      "creating build/lib\n",
      "copying configs.py -> build/lib\n",
      "copying pipeline.py -> build/lib\n",
      "copying train_utils.py -> build/lib\n",
      "copying transform_utils.py -> build/lib\n",
      "installing to /tmp/tmprjs10nqd\n",
      "running install\n",
      "running install_lib\n",
      "copying build/lib/configs.py -> /tmp/tmprjs10nqd\n",
      "copying build/lib/pipeline.py -> /tmp/tmprjs10nqd\n",
      "copying build/lib/train_utils.py -> /tmp/tmprjs10nqd\n",
      "copying build/lib/transform_utils.py -> /tmp/tmprjs10nqd\n",
      "running install_egg_info\n",
      "running egg_info\n",
      "creating tfx_user_code_Trainer.egg-info\n",
      "writing tfx_user_code_Trainer.egg-info/PKG-INFO\n",
      "writing dependency_links to tfx_user_code_Trainer.egg-info/dependency_links.txt\n",
      "writing top-level names to tfx_user_code_Trainer.egg-info/top_level.txt\n",
      "writing manifest file 'tfx_user_code_Trainer.egg-info/SOURCES.txt'\n",
      "reading manifest file 'tfx_user_code_Trainer.egg-info/SOURCES.txt'\n",
      "writing manifest file 'tfx_user_code_Trainer.egg-info/SOURCES.txt'\n",
      "Copying tfx_user_code_Trainer.egg-info to /tmp/tmprjs10nqd/tfx_user_code_Trainer-0.0+3d7dd251b0135438273f0ff7986ed6d732f18a1f0e073c57521aa6ae14a214a5-py3.7.egg-info\n",
      "running install_scripts\n",
      "creating /tmp/tmprjs10nqd/tfx_user_code_Trainer-0.0+3d7dd251b0135438273f0ff7986ed6d732f18a1f0e073c57521aa6ae14a214a5.dist-info/WHEEL\n",
      "creating '/tmp/tmpwfmzlfwx/tfx_user_code_Trainer-0.0+3d7dd251b0135438273f0ff7986ed6d732f18a1f0e073c57521aa6ae14a214a5-py3-none-any.whl' and adding '/tmp/tmprjs10nqd' to it\n",
      "adding 'configs.py'\n",
      "adding 'pipeline.py'\n",
      "adding 'train_utils.py'\n",
      "adding 'transform_utils.py'\n",
      "adding 'tfx_user_code_Trainer-0.0+3d7dd251b0135438273f0ff7986ed6d732f18a1f0e073c57521aa6ae14a214a5.dist-info/METADATA'\n",
      "adding 'tfx_user_code_Trainer-0.0+3d7dd251b0135438273f0ff7986ed6d732f18a1f0e073c57521aa6ae14a214a5.dist-info/WHEEL'\n",
      "adding 'tfx_user_code_Trainer-0.0+3d7dd251b0135438273f0ff7986ed6d732f18a1f0e073c57521aa6ae14a214a5.dist-info/top_level.txt'\n",
      "adding 'tfx_user_code_Trainer-0.0+3d7dd251b0135438273f0ff7986ed6d732f18a1f0e073c57521aa6ae14a214a5.dist-info/RECORD'\n",
      "removing /tmp/tmprjs10nqd\n",
      "INFO:absl:Successfully built user code wheel distribution at 'gs://gcp-bert-aas-kubeflowpipelines-default/tfx_pipeline_output/my_pipeline/_wheels/tfx_user_code_Trainer-0.0+3d7dd251b0135438273f0ff7986ed6d732f18a1f0e073c57521aa6ae14a214a5-py3-none-any.whl'; target user module is 'train_utils'.\n",
      "INFO:absl:Full user module path is 'train_utils@gs://gcp-bert-aas-kubeflowpipelines-default/tfx_pipeline_output/my_pipeline/_wheels/tfx_user_code_Trainer-0.0+3d7dd251b0135438273f0ff7986ed6d732f18a1f0e073c57521aa6ae14a214a5-py3-none-any.whl'\n",
      "INFO:absl:Generated pipeline:\n",
      " pipeline_info {\n",
      "  id: \"my_pipeline\"\n",
      "}\n",
      "nodes {\n",
      "  pipeline_node {\n",
      "    node_info {\n",
      "      type {\n",
      "        name: \"tfx.components.example_gen.csv_example_gen.component.CsvExampleGen\"\n",
      "      }\n",
      "      id: \"CsvExampleGen\"\n",
      "    }\n",
      "    contexts {\n",
      "      contexts {\n",
      "        type {\n",
      "          name: \"pipeline\"\n",
      "        }\n",
      "        name {\n",
      "          field_value {\n",
      "            string_value: \"my_pipeline\"\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "      contexts {\n",
      "        type {\n",
      "          name: \"pipeline_run\"\n",
      "        }\n",
      "        name {\n",
      "          runtime_parameter {\n",
      "            name: \"pipeline_run_id\"\n",
      "            type: STRING\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "      contexts {\n",
      "        type {\n",
      "          name: \"node\"\n",
      "        }\n",
      "        name {\n",
      "          field_value {\n",
      "            string_value: \"my_pipeline.CsvExampleGen\"\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "    outputs {\n",
      "      outputs {\n",
      "        key: \"examples\"\n",
      "        value {\n",
      "          artifact_spec {\n",
      "            type {\n",
      "              name: \"Examples\"\n",
      "              properties {\n",
      "                key: \"span\"\n",
      "                value: INT\n",
      "              }\n",
      "              properties {\n",
      "                key: \"split_names\"\n",
      "                value: STRING\n",
      "              }\n",
      "              properties {\n",
      "                key: \"version\"\n",
      "                value: INT\n",
      "              }\n",
      "            }\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "    parameters {\n",
      "      parameters {\n",
      "        key: \"input_base\"\n",
      "        value {\n",
      "          field_value {\n",
      "            string_value: \"gs://gcp-bert-aas-kubeflowpipelines-default/bert-aas/data/\"\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "      parameters {\n",
      "        key: \"input_config\"\n",
      "        value {\n",
      "          field_value {\n",
      "            string_value: \"{\\n  \\\"splits\\\": [\\n    {\\n      \\\"name\\\": \\\"single_split\\\",\\n      \\\"pattern\\\": \\\"*\\\"\\n    }\\n  ]\\n}\"\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "      parameters {\n",
      "        key: \"output_config\"\n",
      "        value {\n",
      "          field_value {\n",
      "            string_value: \"{\\n  \\\"split_config\\\": {\\n    \\\"splits\\\": [\\n      {\\n        \\\"hash_buckets\\\": 4,\\n        \\\"name\\\": \\\"train\\\"\\n      },\\n      {\\n        \\\"hash_buckets\\\": 1,\\n        \\\"name\\\": \\\"eval\\\"\\n      }\\n    ]\\n  }\\n}\"\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "      parameters {\n",
      "        key: \"output_data_format\"\n",
      "        value {\n",
      "          field_value {\n",
      "            int_value: 6\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "    downstream_nodes: \"Evaluator\"\n",
      "    downstream_nodes: \"InfraValidator\"\n",
      "    downstream_nodes: \"StatisticsGen\"\n",
      "    downstream_nodes: \"Transform\"\n",
      "    execution_options {\n",
      "      caching_options {\n",
      "        enable_cache: true\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "nodes {\n",
      "  pipeline_node {\n",
      "    node_info {\n",
      "      type {\n",
      "        name: \"tfx.dsl.components.common.resolver.Resolver\"\n",
      "      }\n",
      "      id: \"latest_blessed_model_resolver\"\n",
      "    }\n",
      "    contexts {\n",
      "      contexts {\n",
      "        type {\n",
      "          name: \"pipeline\"\n",
      "        }\n",
      "        name {\n",
      "          field_value {\n",
      "            string_value: \"my_pipeline\"\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "      contexts {\n",
      "        type {\n",
      "          name: \"pipeline_run\"\n",
      "        }\n",
      "        name {\n",
      "          runtime_parameter {\n",
      "            name: \"pipeline_run_id\"\n",
      "            type: STRING\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "      contexts {\n",
      "        type {\n",
      "          name: \"node\"\n",
      "        }\n",
      "        name {\n",
      "          field_value {\n",
      "            string_value: \"my_pipeline.latest_blessed_model_resolver\"\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "    inputs {\n",
      "      inputs {\n",
      "        key: \"model\"\n",
      "        value {\n",
      "          channels {\n",
      "            context_queries {\n",
      "              type {\n",
      "                name: \"pipeline\"\n",
      "              }\n",
      "              name {\n",
      "                field_value {\n",
      "                  string_value: \"my_pipeline\"\n",
      "                }\n",
      "              }\n",
      "            }\n",
      "            artifact_query {\n",
      "              type {\n",
      "                name: \"Model\"\n",
      "              }\n",
      "            }\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "      inputs {\n",
      "        key: \"model_blessing\"\n",
      "        value {\n",
      "          channels {\n",
      "            context_queries {\n",
      "              type {\n",
      "                name: \"pipeline\"\n",
      "              }\n",
      "              name {\n",
      "                field_value {\n",
      "                  string_value: \"my_pipeline\"\n",
      "                }\n",
      "              }\n",
      "            }\n",
      "            artifact_query {\n",
      "              type {\n",
      "                name: \"ModelBlessing\"\n",
      "              }\n",
      "            }\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "      resolver_config {\n",
      "        resolver_steps {\n",
      "          class_path: \"tfx.dsl.input_resolution.strategies.latest_blessed_model_strategy.LatestBlessedModelStrategy\"\n",
      "          config_json: \"{}\"\n",
      "          input_keys: \"model\"\n",
      "          input_keys: \"model_blessing\"\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "    downstream_nodes: \"Evaluator\"\n",
      "    execution_options {\n",
      "      caching_options {\n",
      "        enable_cache: true\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "nodes {\n",
      "  pipeline_node {\n",
      "    node_info {\n",
      "      type {\n",
      "        name: \"tfx.components.statistics_gen.component.StatisticsGen\"\n",
      "      }\n",
      "      id: \"StatisticsGen\"\n",
      "    }\n",
      "    contexts {\n",
      "      contexts {\n",
      "        type {\n",
      "          name: \"pipeline\"\n",
      "        }\n",
      "        name {\n",
      "          field_value {\n",
      "            string_value: \"my_pipeline\"\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "      contexts {\n",
      "        type {\n",
      "          name: \"pipeline_run\"\n",
      "        }\n",
      "        name {\n",
      "          runtime_parameter {\n",
      "            name: \"pipeline_run_id\"\n",
      "            type: STRING\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "      contexts {\n",
      "        type {\n",
      "          name: \"node\"\n",
      "        }\n",
      "        name {\n",
      "          field_value {\n",
      "            string_value: \"my_pipeline.StatisticsGen\"\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "    inputs {\n",
      "      inputs {\n",
      "        key: \"examples\"\n",
      "        value {\n",
      "          channels {\n",
      "            producer_node_query {\n",
      "              id: \"CsvExampleGen\"\n",
      "            }\n",
      "            context_queries {\n",
      "              type {\n",
      "                name: \"pipeline\"\n",
      "              }\n",
      "              name {\n",
      "                field_value {\n",
      "                  string_value: \"my_pipeline\"\n",
      "                }\n",
      "              }\n",
      "            }\n",
      "            context_queries {\n",
      "              type {\n",
      "                name: \"pipeline_run\"\n",
      "              }\n",
      "              name {\n",
      "                runtime_parameter {\n",
      "                  name: \"pipeline_run_id\"\n",
      "                  type: STRING\n",
      "                }\n",
      "              }\n",
      "            }\n",
      "            context_queries {\n",
      "              type {\n",
      "                name: \"node\"\n",
      "              }\n",
      "              name {\n",
      "                field_value {\n",
      "                  string_value: \"my_pipeline.CsvExampleGen\"\n",
      "                }\n",
      "              }\n",
      "            }\n",
      "            artifact_query {\n",
      "              type {\n",
      "                name: \"Examples\"\n",
      "              }\n",
      "            }\n",
      "            output_key: \"examples\"\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "    outputs {\n",
      "      outputs {\n",
      "        key: \"statistics\"\n",
      "        value {\n",
      "          artifact_spec {\n",
      "            type {\n",
      "              name: \"ExampleStatistics\"\n",
      "              properties {\n",
      "                key: \"span\"\n",
      "                value: INT\n",
      "              }\n",
      "              properties {\n",
      "                key: \"split_names\"\n",
      "                value: STRING\n",
      "              }\n",
      "            }\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "    parameters {\n",
      "      parameters {\n",
      "        key: \"exclude_splits\"\n",
      "        value {\n",
      "          field_value {\n",
      "            string_value: \"[]\"\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "    upstream_nodes: \"CsvExampleGen\"\n",
      "    downstream_nodes: \"ExampleValidator\"\n",
      "    downstream_nodes: \"SchemaGen\"\n",
      "    execution_options {\n",
      "      caching_options {\n",
      "        enable_cache: true\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "nodes {\n",
      "  pipeline_node {\n",
      "    node_info {\n",
      "      type {\n",
      "        name: \"tfx.components.schema_gen.component.SchemaGen\"\n",
      "      }\n",
      "      id: \"SchemaGen\"\n",
      "    }\n",
      "    contexts {\n",
      "      contexts {\n",
      "        type {\n",
      "          name: \"pipeline\"\n",
      "        }\n",
      "        name {\n",
      "          field_value {\n",
      "            string_value: \"my_pipeline\"\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "      contexts {\n",
      "        type {\n",
      "          name: \"pipeline_run\"\n",
      "        }\n",
      "        name {\n",
      "          runtime_parameter {\n",
      "            name: \"pipeline_run_id\"\n",
      "            type: STRING\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "      contexts {\n",
      "        type {\n",
      "          name: \"node\"\n",
      "        }\n",
      "        name {\n",
      "          field_value {\n",
      "            string_value: \"my_pipeline.SchemaGen\"\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "    inputs {\n",
      "      inputs {\n",
      "        key: \"statistics\"\n",
      "        value {\n",
      "          channels {\n",
      "            producer_node_query {\n",
      "              id: \"StatisticsGen\"\n",
      "            }\n",
      "            context_queries {\n",
      "              type {\n",
      "                name: \"pipeline\"\n",
      "              }\n",
      "              name {\n",
      "                field_value {\n",
      "                  string_value: \"my_pipeline\"\n",
      "                }\n",
      "              }\n",
      "            }\n",
      "            context_queries {\n",
      "              type {\n",
      "                name: \"pipeline_run\"\n",
      "              }\n",
      "              name {\n",
      "                runtime_parameter {\n",
      "                  name: \"pipeline_run_id\"\n",
      "                  type: STRING\n",
      "                }\n",
      "              }\n",
      "            }\n",
      "            context_queries {\n",
      "              type {\n",
      "                name: \"node\"\n",
      "              }\n",
      "              name {\n",
      "                field_value {\n",
      "                  string_value: \"my_pipeline.StatisticsGen\"\n",
      "                }\n",
      "              }\n",
      "            }\n",
      "            artifact_query {\n",
      "              type {\n",
      "                name: \"ExampleStatistics\"\n",
      "              }\n",
      "            }\n",
      "            output_key: \"statistics\"\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "    outputs {\n",
      "      outputs {\n",
      "        key: \"schema\"\n",
      "        value {\n",
      "          artifact_spec {\n",
      "            type {\n",
      "              name: \"Schema\"\n",
      "            }\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "    parameters {\n",
      "      parameters {\n",
      "        key: \"exclude_splits\"\n",
      "        value {\n",
      "          field_value {\n",
      "            string_value: \"[]\"\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "      parameters {\n",
      "        key: \"infer_feature_shape\"\n",
      "        value {\n",
      "          field_value {\n",
      "            int_value: 1\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "    upstream_nodes: \"StatisticsGen\"\n",
      "    downstream_nodes: \"ExampleValidator\"\n",
      "    downstream_nodes: \"Trainer\"\n",
      "    downstream_nodes: \"Transform\"\n",
      "    execution_options {\n",
      "      caching_options {\n",
      "        enable_cache: true\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "nodes {\n",
      "  pipeline_node {\n",
      "    node_info {\n",
      "      type {\n",
      "        name: \"tfx.components.example_validator.component.ExampleValidator\"\n",
      "      }\n",
      "      id: \"ExampleValidator\"\n",
      "    }\n",
      "    contexts {\n",
      "      contexts {\n",
      "        type {\n",
      "          name: \"pipeline\"\n",
      "        }\n",
      "        name {\n",
      "          field_value {\n",
      "            string_value: \"my_pipeline\"\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "      contexts {\n",
      "        type {\n",
      "          name: \"pipeline_run\"\n",
      "        }\n",
      "        name {\n",
      "          runtime_parameter {\n",
      "            name: \"pipeline_run_id\"\n",
      "            type: STRING\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "      contexts {\n",
      "        type {\n",
      "          name: \"node\"\n",
      "        }\n",
      "        name {\n",
      "          field_value {\n",
      "            string_value: \"my_pipeline.ExampleValidator\"\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "    inputs {\n",
      "      inputs {\n",
      "        key: \"schema\"\n",
      "        value {\n",
      "          channels {\n",
      "            producer_node_query {\n",
      "              id: \"SchemaGen\"\n",
      "            }\n",
      "            context_queries {\n",
      "              type {\n",
      "                name: \"pipeline\"\n",
      "              }\n",
      "              name {\n",
      "                field_value {\n",
      "                  string_value: \"my_pipeline\"\n",
      "                }\n",
      "              }\n",
      "            }\n",
      "            context_queries {\n",
      "              type {\n",
      "                name: \"pipeline_run\"\n",
      "              }\n",
      "              name {\n",
      "                runtime_parameter {\n",
      "                  name: \"pipeline_run_id\"\n",
      "                  type: STRING\n",
      "                }\n",
      "              }\n",
      "            }\n",
      "            context_queries {\n",
      "              type {\n",
      "                name: \"node\"\n",
      "              }\n",
      "              name {\n",
      "                field_value {\n",
      "                  string_value: \"my_pipeline.SchemaGen\"\n",
      "                }\n",
      "              }\n",
      "            }\n",
      "            artifact_query {\n",
      "              type {\n",
      "                name: \"Schema\"\n",
      "              }\n",
      "            }\n",
      "            output_key: \"schema\"\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "      inputs {\n",
      "        key: \"statistics\"\n",
      "        value {\n",
      "          channels {\n",
      "            producer_node_query {\n",
      "              id: \"StatisticsGen\"\n",
      "            }\n",
      "            context_queries {\n",
      "              type {\n",
      "                name: \"pipeline\"\n",
      "              }\n",
      "              name {\n",
      "                field_value {\n",
      "                  string_value: \"my_pipeline\"\n",
      "                }\n",
      "              }\n",
      "            }\n",
      "            context_queries {\n",
      "              type {\n",
      "                name: \"pipeline_run\"\n",
      "              }\n",
      "              name {\n",
      "                runtime_parameter {\n",
      "                  name: \"pipeline_run_id\"\n",
      "                  type: STRING\n",
      "                }\n",
      "              }\n",
      "            }\n",
      "            context_queries {\n",
      "              type {\n",
      "                name: \"node\"\n",
      "              }\n",
      "              name {\n",
      "                field_value {\n",
      "                  string_value: \"my_pipeline.StatisticsGen\"\n",
      "                }\n",
      "              }\n",
      "            }\n",
      "            artifact_query {\n",
      "              type {\n",
      "                name: \"ExampleStatistics\"\n",
      "              }\n",
      "            }\n",
      "            output_key: \"statistics\"\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "    outputs {\n",
      "      outputs {\n",
      "        key: \"anomalies\"\n",
      "        value {\n",
      "          artifact_spec {\n",
      "            type {\n",
      "              name: \"ExampleAnomalies\"\n",
      "              properties {\n",
      "                key: \"span\"\n",
      "                value: INT\n",
      "              }\n",
      "              properties {\n",
      "                key: \"split_names\"\n",
      "                value: STRING\n",
      "              }\n",
      "            }\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "    parameters {\n",
      "      parameters {\n",
      "        key: \"exclude_splits\"\n",
      "        value {\n",
      "          field_value {\n",
      "            string_value: \"[]\"\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "    upstream_nodes: \"SchemaGen\"\n",
      "    upstream_nodes: \"StatisticsGen\"\n",
      "    execution_options {\n",
      "      caching_options {\n",
      "        enable_cache: true\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "nodes {\n",
      "  pipeline_node {\n",
      "    node_info {\n",
      "      type {\n",
      "        name: \"tfx.components.transform.component.Transform\"\n",
      "      }\n",
      "      id: \"Transform\"\n",
      "    }\n",
      "    contexts {\n",
      "      contexts {\n",
      "        type {\n",
      "          name: \"pipeline\"\n",
      "        }\n",
      "        name {\n",
      "          field_value {\n",
      "            string_value: \"my_pipeline\"\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "      contexts {\n",
      "        type {\n",
      "          name: \"pipeline_run\"\n",
      "        }\n",
      "        name {\n",
      "          runtime_parameter {\n",
      "            name: \"pipeline_run_id\"\n",
      "            type: STRING\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "      contexts {\n",
      "        type {\n",
      "          name: \"node\"\n",
      "        }\n",
      "        name {\n",
      "          field_value {\n",
      "            string_value: \"my_pipeline.Transform\"\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "    inputs {\n",
      "      inputs {\n",
      "        key: \"examples\"\n",
      "        value {\n",
      "          channels {\n",
      "            producer_node_query {\n",
      "              id: \"CsvExampleGen\"\n",
      "            }\n",
      "            context_queries {\n",
      "              type {\n",
      "                name: \"pipeline\"\n",
      "              }\n",
      "              name {\n",
      "                field_value {\n",
      "                  string_value: \"my_pipeline\"\n",
      "                }\n",
      "              }\n",
      "            }\n",
      "            context_queries {\n",
      "              type {\n",
      "                name: \"pipeline_run\"\n",
      "              }\n",
      "              name {\n",
      "                runtime_parameter {\n",
      "                  name: \"pipeline_run_id\"\n",
      "                  type: STRING\n",
      "                }\n",
      "              }\n",
      "            }\n",
      "            context_queries {\n",
      "              type {\n",
      "                name: \"node\"\n",
      "              }\n",
      "              name {\n",
      "                field_value {\n",
      "                  string_value: \"my_pipeline.CsvExampleGen\"\n",
      "                }\n",
      "              }\n",
      "            }\n",
      "            artifact_query {\n",
      "              type {\n",
      "                name: \"Examples\"\n",
      "              }\n",
      "            }\n",
      "            output_key: \"examples\"\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "      inputs {\n",
      "        key: \"schema\"\n",
      "        value {\n",
      "          channels {\n",
      "            producer_node_query {\n",
      "              id: \"SchemaGen\"\n",
      "            }\n",
      "            context_queries {\n",
      "              type {\n",
      "                name: \"pipeline\"\n",
      "              }\n",
      "              name {\n",
      "                field_value {\n",
      "                  string_value: \"my_pipeline\"\n",
      "                }\n",
      "              }\n",
      "            }\n",
      "            context_queries {\n",
      "              type {\n",
      "                name: \"pipeline_run\"\n",
      "              }\n",
      "              name {\n",
      "                runtime_parameter {\n",
      "                  name: \"pipeline_run_id\"\n",
      "                  type: STRING\n",
      "                }\n",
      "              }\n",
      "            }\n",
      "            context_queries {\n",
      "              type {\n",
      "                name: \"node\"\n",
      "              }\n",
      "              name {\n",
      "                field_value {\n",
      "                  string_value: \"my_pipeline.SchemaGen\"\n",
      "                }\n",
      "              }\n",
      "            }\n",
      "            artifact_query {\n",
      "              type {\n",
      "                name: \"Schema\"\n",
      "              }\n",
      "            }\n",
      "            output_key: \"schema\"\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "    outputs {\n",
      "      outputs {\n",
      "        key: \"post_transform_anomalies\"\n",
      "        value {\n",
      "          artifact_spec {\n",
      "            type {\n",
      "              name: \"ExampleAnomalies\"\n",
      "              properties {\n",
      "                key: \"span\"\n",
      "                value: INT\n",
      "              }\n",
      "              properties {\n",
      "                key: \"split_names\"\n",
      "                value: STRING\n",
      "              }\n",
      "            }\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "      outputs {\n",
      "        key: \"post_transform_schema\"\n",
      "        value {\n",
      "          artifact_spec {\n",
      "            type {\n",
      "              name: \"Schema\"\n",
      "            }\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "      outputs {\n",
      "        key: \"post_transform_stats\"\n",
      "        value {\n",
      "          artifact_spec {\n",
      "            type {\n",
      "              name: \"ExampleStatistics\"\n",
      "              properties {\n",
      "                key: \"span\"\n",
      "                value: INT\n",
      "              }\n",
      "              properties {\n",
      "                key: \"split_names\"\n",
      "                value: STRING\n",
      "              }\n",
      "            }\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "      outputs {\n",
      "        key: \"pre_transform_schema\"\n",
      "        value {\n",
      "          artifact_spec {\n",
      "            type {\n",
      "              name: \"Schema\"\n",
      "            }\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "      outputs {\n",
      "        key: \"pre_transform_stats\"\n",
      "        value {\n",
      "          artifact_spec {\n",
      "            type {\n",
      "              name: \"ExampleStatistics\"\n",
      "              properties {\n",
      "                key: \"span\"\n",
      "                value: INT\n",
      "              }\n",
      "              properties {\n",
      "                key: \"split_names\"\n",
      "                value: STRING\n",
      "              }\n",
      "            }\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "      outputs {\n",
      "        key: \"transform_graph\"\n",
      "        value {\n",
      "          artifact_spec {\n",
      "            type {\n",
      "              name: \"TransformGraph\"\n",
      "            }\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "      outputs {\n",
      "        key: \"transformed_examples\"\n",
      "        value {\n",
      "          artifact_spec {\n",
      "            type {\n",
      "              name: \"Examples\"\n",
      "              properties {\n",
      "                key: \"span\"\n",
      "                value: INT\n",
      "              }\n",
      "              properties {\n",
      "                key: \"split_names\"\n",
      "                value: STRING\n",
      "              }\n",
      "              properties {\n",
      "                key: \"version\"\n",
      "                value: INT\n",
      "              }\n",
      "            }\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "      outputs {\n",
      "        key: \"updated_analyzer_cache\"\n",
      "        value {\n",
      "          artifact_spec {\n",
      "            type {\n",
      "              name: \"TransformCache\"\n",
      "            }\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "    parameters {\n",
      "      parameters {\n",
      "        key: \"custom_config\"\n",
      "        value {\n",
      "          field_value {\n",
      "            string_value: \"null\"\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "      parameters {\n",
      "        key: \"disable_statistics\"\n",
      "        value {\n",
      "          field_value {\n",
      "            int_value: 0\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "      parameters {\n",
      "        key: \"force_tf_compat_v1\"\n",
      "        value {\n",
      "          field_value {\n",
      "            int_value: 0\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "      parameters {\n",
      "        key: \"module_path\"\n",
      "        value {\n",
      "          field_value {\n",
      "            string_value: \"transform_utils@gs://gcp-bert-aas-kubeflowpipelines-default/tfx_pipeline_output/my_pipeline/_wheels/tfx_user_code_Transform-0.0+3d7dd251b0135438273f0ff7986ed6d732f18a1f0e073c57521aa6ae14a214a5-py3-none-any.whl\"\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "    upstream_nodes: \"CsvExampleGen\"\n",
      "    upstream_nodes: \"SchemaGen\"\n",
      "    downstream_nodes: \"Trainer\"\n",
      "    downstream_nodes: \"Tuner\"\n",
      "    execution_options {\n",
      "      caching_options {\n",
      "        enable_cache: true\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "nodes {\n",
      "  pipeline_node {\n",
      "    node_info {\n",
      "      type {\n",
      "        name: \"tfx.components.tuner.component.Tuner\"\n",
      "      }\n",
      "      id: \"Tuner\"\n",
      "    }\n",
      "    contexts {\n",
      "      contexts {\n",
      "        type {\n",
      "          name: \"pipeline\"\n",
      "        }\n",
      "        name {\n",
      "          field_value {\n",
      "            string_value: \"my_pipeline\"\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "      contexts {\n",
      "        type {\n",
      "          name: \"pipeline_run\"\n",
      "        }\n",
      "        name {\n",
      "          runtime_parameter {\n",
      "            name: \"pipeline_run_id\"\n",
      "            type: STRING\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "      contexts {\n",
      "        type {\n",
      "          name: \"node\"\n",
      "        }\n",
      "        name {\n",
      "          field_value {\n",
      "            string_value: \"my_pipeline.Tuner\"\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "    inputs {\n",
      "      inputs {\n",
      "        key: \"examples\"\n",
      "        value {\n",
      "          channels {\n",
      "            producer_node_query {\n",
      "              id: \"Transform\"\n",
      "            }\n",
      "            context_queries {\n",
      "              type {\n",
      "                name: \"pipeline\"\n",
      "              }\n",
      "              name {\n",
      "                field_value {\n",
      "                  string_value: \"my_pipeline\"\n",
      "                }\n",
      "              }\n",
      "            }\n",
      "            context_queries {\n",
      "              type {\n",
      "                name: \"pipeline_run\"\n",
      "              }\n",
      "              name {\n",
      "                runtime_parameter {\n",
      "                  name: \"pipeline_run_id\"\n",
      "                  type: STRING\n",
      "                }\n",
      "              }\n",
      "            }\n",
      "            context_queries {\n",
      "              type {\n",
      "                name: \"node\"\n",
      "              }\n",
      "              name {\n",
      "                field_value {\n",
      "                  string_value: \"my_pipeline.Transform\"\n",
      "                }\n",
      "              }\n",
      "            }\n",
      "            artifact_query {\n",
      "              type {\n",
      "                name: \"Examples\"\n",
      "              }\n",
      "            }\n",
      "            output_key: \"transformed_examples\"\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "      inputs {\n",
      "        key: \"transform_graph\"\n",
      "        value {\n",
      "          channels {\n",
      "            producer_node_query {\n",
      "              id: \"Transform\"\n",
      "            }\n",
      "            context_queries {\n",
      "              type {\n",
      "                name: \"pipeline\"\n",
      "              }\n",
      "              name {\n",
      "                field_value {\n",
      "                  string_value: \"my_pipeline\"\n",
      "                }\n",
      "              }\n",
      "            }\n",
      "            context_queries {\n",
      "              type {\n",
      "                name: \"pipeline_run\"\n",
      "              }\n",
      "              name {\n",
      "                runtime_parameter {\n",
      "                  name: \"pipeline_run_id\"\n",
      "                  type: STRING\n",
      "                }\n",
      "              }\n",
      "            }\n",
      "            context_queries {\n",
      "              type {\n",
      "                name: \"node\"\n",
      "              }\n",
      "              name {\n",
      "                field_value {\n",
      "                  string_value: \"my_pipeline.Transform\"\n",
      "                }\n",
      "              }\n",
      "            }\n",
      "            artifact_query {\n",
      "              type {\n",
      "                name: \"TransformGraph\"\n",
      "              }\n",
      "            }\n",
      "            output_key: \"transform_graph\"\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "    outputs {\n",
      "      outputs {\n",
      "        key: \"best_hyperparameters\"\n",
      "        value {\n",
      "          artifact_spec {\n",
      "            type {\n",
      "              name: \"HyperParameters\"\n",
      "            }\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "    parameters {\n",
      "      parameters {\n",
      "        key: \"custom_config\"\n",
      "        value {\n",
      "          field_value {\n",
      "            string_value: \"null\"\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "      parameters {\n",
      "        key: \"eval_args\"\n",
      "        value {\n",
      "          field_value {\n",
      "            string_value: \"{\\n  \\\"num_steps\\\": 5\\n}\"\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "      parameters {\n",
      "        key: \"module_path\"\n",
      "        value {\n",
      "          field_value {\n",
      "            string_value: \"train_utils@gs://gcp-bert-aas-kubeflowpipelines-default/tfx_pipeline_output/my_pipeline/_wheels/tfx_user_code_Tuner-0.0+3d7dd251b0135438273f0ff7986ed6d732f18a1f0e073c57521aa6ae14a214a5-py3-none-any.whl\"\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "      parameters {\n",
      "        key: \"train_args\"\n",
      "        value {\n",
      "          field_value {\n",
      "            string_value: \"{\\n  \\\"num_steps\\\": 10\\n}\"\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "    upstream_nodes: \"Transform\"\n",
      "    downstream_nodes: \"Trainer\"\n",
      "    execution_options {\n",
      "      caching_options {\n",
      "        enable_cache: true\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "nodes {\n",
      "  pipeline_node {\n",
      "    node_info {\n",
      "      type {\n",
      "        name: \"tfx.components.trainer.component.Trainer\"\n",
      "      }\n",
      "      id: \"Trainer\"\n",
      "    }\n",
      "    contexts {\n",
      "      contexts {\n",
      "        type {\n",
      "          name: \"pipeline\"\n",
      "        }\n",
      "        name {\n",
      "          field_value {\n",
      "            string_value: \"my_pipeline\"\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "      contexts {\n",
      "        type {\n",
      "          name: \"pipeline_run\"\n",
      "        }\n",
      "        name {\n",
      "          runtime_parameter {\n",
      "            name: \"pipeline_run_id\"\n",
      "            type: STRING\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "      contexts {\n",
      "        type {\n",
      "          name: \"node\"\n",
      "        }\n",
      "        name {\n",
      "          field_value {\n",
      "            string_value: \"my_pipeline.Trainer\"\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "    inputs {\n",
      "      inputs {\n",
      "        key: \"examples\"\n",
      "        value {\n",
      "          channels {\n",
      "            producer_node_query {\n",
      "              id: \"Transform\"\n",
      "            }\n",
      "            context_queries {\n",
      "              type {\n",
      "                name: \"pipeline\"\n",
      "              }\n",
      "              name {\n",
      "                field_value {\n",
      "                  string_value: \"my_pipeline\"\n",
      "                }\n",
      "              }\n",
      "            }\n",
      "            context_queries {\n",
      "              type {\n",
      "                name: \"pipeline_run\"\n",
      "              }\n",
      "              name {\n",
      "                runtime_parameter {\n",
      "                  name: \"pipeline_run_id\"\n",
      "                  type: STRING\n",
      "                }\n",
      "              }\n",
      "            }\n",
      "            context_queries {\n",
      "              type {\n",
      "                name: \"node\"\n",
      "              }\n",
      "              name {\n",
      "                field_value {\n",
      "                  string_value: \"my_pipeline.Transform\"\n",
      "                }\n",
      "              }\n",
      "            }\n",
      "            artifact_query {\n",
      "              type {\n",
      "                name: \"Examples\"\n",
      "              }\n",
      "            }\n",
      "            output_key: \"transformed_examples\"\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "      inputs {\n",
      "        key: \"hyperparameters\"\n",
      "        value {\n",
      "          channels {\n",
      "            producer_node_query {\n",
      "              id: \"Tuner\"\n",
      "            }\n",
      "            context_queries {\n",
      "              type {\n",
      "                name: \"pipeline\"\n",
      "              }\n",
      "              name {\n",
      "                field_value {\n",
      "                  string_value: \"my_pipeline\"\n",
      "                }\n",
      "              }\n",
      "            }\n",
      "            context_queries {\n",
      "              type {\n",
      "                name: \"pipeline_run\"\n",
      "              }\n",
      "              name {\n",
      "                runtime_parameter {\n",
      "                  name: \"pipeline_run_id\"\n",
      "                  type: STRING\n",
      "                }\n",
      "              }\n",
      "            }\n",
      "            context_queries {\n",
      "              type {\n",
      "                name: \"node\"\n",
      "              }\n",
      "              name {\n",
      "                field_value {\n",
      "                  string_value: \"my_pipeline.Tuner\"\n",
      "                }\n",
      "              }\n",
      "            }\n",
      "            artifact_query {\n",
      "              type {\n",
      "                name: \"HyperParameters\"\n",
      "              }\n",
      "            }\n",
      "            output_key: \"best_hyperparameters\"\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "      inputs {\n",
      "        key: \"schema\"\n",
      "        value {\n",
      "          channels {\n",
      "            producer_node_query {\n",
      "              id: \"SchemaGen\"\n",
      "            }\n",
      "            context_queries {\n",
      "              type {\n",
      "                name: \"pipeline\"\n",
      "              }\n",
      "              name {\n",
      "                field_value {\n",
      "                  string_value: \"my_pipeline\"\n",
      "                }\n",
      "              }\n",
      "            }\n",
      "            context_queries {\n",
      "              type {\n",
      "                name: \"pipeline_run\"\n",
      "              }\n",
      "              name {\n",
      "                runtime_parameter {\n",
      "                  name: \"pipeline_run_id\"\n",
      "                  type: STRING\n",
      "                }\n",
      "              }\n",
      "            }\n",
      "            context_queries {\n",
      "              type {\n",
      "                name: \"node\"\n",
      "              }\n",
      "              name {\n",
      "                field_value {\n",
      "                  string_value: \"my_pipeline.SchemaGen\"\n",
      "                }\n",
      "              }\n",
      "            }\n",
      "            artifact_query {\n",
      "              type {\n",
      "                name: \"Schema\"\n",
      "              }\n",
      "            }\n",
      "            output_key: \"schema\"\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "      inputs {\n",
      "        key: \"transform_graph\"\n",
      "        value {\n",
      "          channels {\n",
      "            producer_node_query {\n",
      "              id: \"Transform\"\n",
      "            }\n",
      "            context_queries {\n",
      "              type {\n",
      "                name: \"pipeline\"\n",
      "              }\n",
      "              name {\n",
      "                field_value {\n",
      "                  string_value: \"my_pipeline\"\n",
      "                }\n",
      "              }\n",
      "            }\n",
      "            context_queries {\n",
      "              type {\n",
      "                name: \"pipeline_run\"\n",
      "              }\n",
      "              name {\n",
      "                runtime_parameter {\n",
      "                  name: \"pipeline_run_id\"\n",
      "                  type: STRING\n",
      "                }\n",
      "              }\n",
      "            }\n",
      "            context_queries {\n",
      "              type {\n",
      "                name: \"node\"\n",
      "              }\n",
      "              name {\n",
      "                field_value {\n",
      "                  string_value: \"my_pipeline.Transform\"\n",
      "                }\n",
      "              }\n",
      "            }\n",
      "            artifact_query {\n",
      "              type {\n",
      "                name: \"TransformGraph\"\n",
      "              }\n",
      "            }\n",
      "            output_key: \"transform_graph\"\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "    outputs {\n",
      "      outputs {\n",
      "        key: \"model\"\n",
      "        value {\n",
      "          artifact_spec {\n",
      "            type {\n",
      "              name: \"Model\"\n",
      "            }\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "      outputs {\n",
      "        key: \"model_run\"\n",
      "        value {\n",
      "          artifact_spec {\n",
      "            type {\n",
      "              name: \"ModelRun\"\n",
      "            }\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "    parameters {\n",
      "      parameters {\n",
      "        key: \"custom_config\"\n",
      "        value {\n",
      "          field_value {\n",
      "            string_value: \"null\"\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "      parameters {\n",
      "        key: \"eval_args\"\n",
      "        value {\n",
      "          field_value {\n",
      "            string_value: \"{\\n  \\\"num_steps\\\": 5\\n}\"\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "      parameters {\n",
      "        key: \"module_path\"\n",
      "        value {\n",
      "          field_value {\n",
      "            string_value: \"train_utils@gs://gcp-bert-aas-kubeflowpipelines-default/tfx_pipeline_output/my_pipeline/_wheels/tfx_user_code_Trainer-0.0+3d7dd251b0135438273f0ff7986ed6d732f18a1f0e073c57521aa6ae14a214a5-py3-none-any.whl\"\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "      parameters {\n",
      "        key: \"train_args\"\n",
      "        value {\n",
      "          field_value {\n",
      "            string_value: \"{\\n  \\\"num_steps\\\": 10\\n}\"\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "    upstream_nodes: \"SchemaGen\"\n",
      "    upstream_nodes: \"Transform\"\n",
      "    upstream_nodes: \"Tuner\"\n",
      "    downstream_nodes: \"Evaluator\"\n",
      "    downstream_nodes: \"InfraValidator\"\n",
      "    downstream_nodes: \"Pusher\"\n",
      "    execution_options {\n",
      "      caching_options {\n",
      "        enable_cache: true\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "nodes {\n",
      "  pipeline_node {\n",
      "    node_info {\n",
      "      type {\n",
      "        name: \"tfx.components.evaluator.component.Evaluator\"\n",
      "      }\n",
      "      id: \"Evaluator\"\n",
      "    }\n",
      "    contexts {\n",
      "      contexts {\n",
      "        type {\n",
      "          name: \"pipeline\"\n",
      "        }\n",
      "        name {\n",
      "          field_value {\n",
      "            string_value: \"my_pipeline\"\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "      contexts {\n",
      "        type {\n",
      "          name: \"pipeline_run\"\n",
      "        }\n",
      "        name {\n",
      "          runtime_parameter {\n",
      "            name: \"pipeline_run_id\"\n",
      "            type: STRING\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "      contexts {\n",
      "        type {\n",
      "          name: \"node\"\n",
      "        }\n",
      "        name {\n",
      "          field_value {\n",
      "            string_value: \"my_pipeline.Evaluator\"\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "    inputs {\n",
      "      inputs {\n",
      "        key: \"baseline_model\"\n",
      "        value {\n",
      "          channels {\n",
      "            producer_node_query {\n",
      "              id: \"latest_blessed_model_resolver\"\n",
      "            }\n",
      "            context_queries {\n",
      "              type {\n",
      "                name: \"pipeline\"\n",
      "              }\n",
      "              name {\n",
      "                field_value {\n",
      "                  string_value: \"my_pipeline\"\n",
      "                }\n",
      "              }\n",
      "            }\n",
      "            context_queries {\n",
      "              type {\n",
      "                name: \"pipeline_run\"\n",
      "              }\n",
      "              name {\n",
      "                runtime_parameter {\n",
      "                  name: \"pipeline_run_id\"\n",
      "                  type: STRING\n",
      "                }\n",
      "              }\n",
      "            }\n",
      "            context_queries {\n",
      "              type {\n",
      "                name: \"node\"\n",
      "              }\n",
      "              name {\n",
      "                field_value {\n",
      "                  string_value: \"my_pipeline.latest_blessed_model_resolver\"\n",
      "                }\n",
      "              }\n",
      "            }\n",
      "            artifact_query {\n",
      "              type {\n",
      "                name: \"Model\"\n",
      "              }\n",
      "            }\n",
      "            output_key: \"model\"\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "      inputs {\n",
      "        key: \"examples\"\n",
      "        value {\n",
      "          channels {\n",
      "            producer_node_query {\n",
      "              id: \"CsvExampleGen\"\n",
      "            }\n",
      "            context_queries {\n",
      "              type {\n",
      "                name: \"pipeline\"\n",
      "              }\n",
      "              name {\n",
      "                field_value {\n",
      "                  string_value: \"my_pipeline\"\n",
      "                }\n",
      "              }\n",
      "            }\n",
      "            context_queries {\n",
      "              type {\n",
      "                name: \"pipeline_run\"\n",
      "              }\n",
      "              name {\n",
      "                runtime_parameter {\n",
      "                  name: \"pipeline_run_id\"\n",
      "                  type: STRING\n",
      "                }\n",
      "              }\n",
      "            }\n",
      "            context_queries {\n",
      "              type {\n",
      "                name: \"node\"\n",
      "              }\n",
      "              name {\n",
      "                field_value {\n",
      "                  string_value: \"my_pipeline.CsvExampleGen\"\n",
      "                }\n",
      "              }\n",
      "            }\n",
      "            artifact_query {\n",
      "              type {\n",
      "                name: \"Examples\"\n",
      "              }\n",
      "            }\n",
      "            output_key: \"examples\"\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "      inputs {\n",
      "        key: \"model\"\n",
      "        value {\n",
      "          channels {\n",
      "            producer_node_query {\n",
      "              id: \"Trainer\"\n",
      "            }\n",
      "            context_queries {\n",
      "              type {\n",
      "                name: \"pipeline\"\n",
      "              }\n",
      "              name {\n",
      "                field_value {\n",
      "                  string_value: \"my_pipeline\"\n",
      "                }\n",
      "              }\n",
      "            }\n",
      "            context_queries {\n",
      "              type {\n",
      "                name: \"pipeline_run\"\n",
      "              }\n",
      "              name {\n",
      "                runtime_parameter {\n",
      "                  name: \"pipeline_run_id\"\n",
      "                  type: STRING\n",
      "                }\n",
      "              }\n",
      "            }\n",
      "            context_queries {\n",
      "              type {\n",
      "                name: \"node\"\n",
      "              }\n",
      "              name {\n",
      "                field_value {\n",
      "                  string_value: \"my_pipeline.Trainer\"\n",
      "                }\n",
      "              }\n",
      "            }\n",
      "            artifact_query {\n",
      "              type {\n",
      "                name: \"Model\"\n",
      "              }\n",
      "            }\n",
      "            output_key: \"model\"\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "    outputs {\n",
      "      outputs {\n",
      "        key: \"blessing\"\n",
      "        value {\n",
      "          artifact_spec {\n",
      "            type {\n",
      "              name: \"ModelBlessing\"\n",
      "            }\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "      outputs {\n",
      "        key: \"evaluation\"\n",
      "        value {\n",
      "          artifact_spec {\n",
      "            type {\n",
      "              name: \"ModelEvaluation\"\n",
      "            }\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "    parameters {\n",
      "      parameters {\n",
      "        key: \"eval_config\"\n",
      "        value {\n",
      "          field_value {\n",
      "            string_value: \"{\\n  \\\"metrics_specs\\\": [\\n    {\\n      \\\"metrics\\\": [\\n        {\\n          \\\"class_name\\\": \\\"BinaryAccuracy\\\",\\n          \\\"threshold\\\": {\\n            \\\"change_threshold\\\": {\\n              \\\"absolute\\\": -0.01,\\n              \\\"direction\\\": \\\"HIGHER_IS_BETTER\\\"\\n            },\\n            \\\"value_threshold\\\": {\\n              \\\"lower_bound\\\": 0.01\\n            }\\n          }\\n        }\\n      ]\\n    }\\n  ],\\n  \\\"model_specs\\\": [\\n    {\\n      \\\"label_key\\\": \\\"sentiment\\\"\\n    }\\n  ],\\n  \\\"slicing_specs\\\": [\\n    {},\\n    {\\n      \\\"feature_keys\\\": [\\n        \\\"sentiment\\\"\\n      ]\\n    }\\n  ]\\n}\"\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "      parameters {\n",
      "        key: \"example_splits\"\n",
      "        value {\n",
      "          field_value {\n",
      "            string_value: \"null\"\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "    upstream_nodes: \"CsvExampleGen\"\n",
      "    upstream_nodes: \"Trainer\"\n",
      "    upstream_nodes: \"latest_blessed_model_resolver\"\n",
      "    downstream_nodes: \"Pusher\"\n",
      "    execution_options {\n",
      "      caching_options {\n",
      "        enable_cache: true\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "nodes {\n",
      "  pipeline_node {\n",
      "    node_info {\n",
      "      type {\n",
      "        name: \"tfx.components.infra_validator.component.InfraValidator\"\n",
      "      }\n",
      "      id: \"InfraValidator\"\n",
      "    }\n",
      "    contexts {\n",
      "      contexts {\n",
      "        type {\n",
      "          name: \"pipeline\"\n",
      "        }\n",
      "        name {\n",
      "          field_value {\n",
      "            string_value: \"my_pipeline\"\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "      contexts {\n",
      "        type {\n",
      "          name: \"pipeline_run\"\n",
      "        }\n",
      "        name {\n",
      "          runtime_parameter {\n",
      "            name: \"pipeline_run_id\"\n",
      "            type: STRING\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "      contexts {\n",
      "        type {\n",
      "          name: \"node\"\n",
      "        }\n",
      "        name {\n",
      "          field_value {\n",
      "            string_value: \"my_pipeline.InfraValidator\"\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "    inputs {\n",
      "      inputs {\n",
      "        key: \"examples\"\n",
      "        value {\n",
      "          channels {\n",
      "            producer_node_query {\n",
      "              id: \"CsvExampleGen\"\n",
      "            }\n",
      "            context_queries {\n",
      "              type {\n",
      "                name: \"pipeline\"\n",
      "              }\n",
      "              name {\n",
      "                field_value {\n",
      "                  string_value: \"my_pipeline\"\n",
      "                }\n",
      "              }\n",
      "            }\n",
      "            context_queries {\n",
      "              type {\n",
      "                name: \"pipeline_run\"\n",
      "              }\n",
      "              name {\n",
      "                runtime_parameter {\n",
      "                  name: \"pipeline_run_id\"\n",
      "                  type: STRING\n",
      "                }\n",
      "              }\n",
      "            }\n",
      "            context_queries {\n",
      "              type {\n",
      "                name: \"node\"\n",
      "              }\n",
      "              name {\n",
      "                field_value {\n",
      "                  string_value: \"my_pipeline.CsvExampleGen\"\n",
      "                }\n",
      "              }\n",
      "            }\n",
      "            artifact_query {\n",
      "              type {\n",
      "                name: \"Examples\"\n",
      "              }\n",
      "            }\n",
      "            output_key: \"examples\"\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "      inputs {\n",
      "        key: \"model\"\n",
      "        value {\n",
      "          channels {\n",
      "            producer_node_query {\n",
      "              id: \"Trainer\"\n",
      "            }\n",
      "            context_queries {\n",
      "              type {\n",
      "                name: \"pipeline\"\n",
      "              }\n",
      "              name {\n",
      "                field_value {\n",
      "                  string_value: \"my_pipeline\"\n",
      "                }\n",
      "              }\n",
      "            }\n",
      "            context_queries {\n",
      "              type {\n",
      "                name: \"pipeline_run\"\n",
      "              }\n",
      "              name {\n",
      "                runtime_parameter {\n",
      "                  name: \"pipeline_run_id\"\n",
      "                  type: STRING\n",
      "                }\n",
      "              }\n",
      "            }\n",
      "            context_queries {\n",
      "              type {\n",
      "                name: \"node\"\n",
      "              }\n",
      "              name {\n",
      "                field_value {\n",
      "                  string_value: \"my_pipeline.Trainer\"\n",
      "                }\n",
      "              }\n",
      "            }\n",
      "            artifact_query {\n",
      "              type {\n",
      "                name: \"Model\"\n",
      "              }\n",
      "            }\n",
      "            output_key: \"model\"\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "    outputs {\n",
      "      outputs {\n",
      "        key: \"blessing\"\n",
      "        value {\n",
      "          artifact_spec {\n",
      "            type {\n",
      "              name: \"InfraBlessing\"\n",
      "            }\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "    parameters {\n",
      "      parameters {\n",
      "        key: \"request_spec\"\n",
      "        value {\n",
      "          field_value {\n",
      "            string_value: \"{\\n  \\\"tensorflow_serving\\\": {}\\n}\"\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "      parameters {\n",
      "        key: \"serving_spec\"\n",
      "        value {\n",
      "          field_value {\n",
      "            string_value: \"{\\n  \\\"kubernetes\\\": {},\\n  \\\"tensorflow_serving\\\": {\\n    \\\"tags\\\": [\\n      \\\"latest\\\"\\n    ]\\n  }\\n}\"\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "    upstream_nodes: \"CsvExampleGen\"\n",
      "    upstream_nodes: \"Trainer\"\n",
      "    downstream_nodes: \"Pusher\"\n",
      "    execution_options {\n",
      "      caching_options {\n",
      "        enable_cache: true\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "nodes {\n",
      "  pipeline_node {\n",
      "    node_info {\n",
      "      type {\n",
      "        name: \"tfx.components.pusher.component.Pusher\"\n",
      "      }\n",
      "      id: \"Pusher\"\n",
      "    }\n",
      "    contexts {\n",
      "      contexts {\n",
      "        type {\n",
      "          name: \"pipeline\"\n",
      "        }\n",
      "        name {\n",
      "          field_value {\n",
      "            string_value: \"my_pipeline\"\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "      contexts {\n",
      "        type {\n",
      "          name: \"pipeline_run\"\n",
      "        }\n",
      "        name {\n",
      "          runtime_parameter {\n",
      "            name: \"pipeline_run_id\"\n",
      "            type: STRING\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "      contexts {\n",
      "        type {\n",
      "          name: \"node\"\n",
      "        }\n",
      "        name {\n",
      "          field_value {\n",
      "            string_value: \"my_pipeline.Pusher\"\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "    inputs {\n",
      "      inputs {\n",
      "        key: \"infra_blessing\"\n",
      "        value {\n",
      "          channels {\n",
      "            producer_node_query {\n",
      "              id: \"InfraValidator\"\n",
      "            }\n",
      "            context_queries {\n",
      "              type {\n",
      "                name: \"pipeline\"\n",
      "              }\n",
      "              name {\n",
      "                field_value {\n",
      "                  string_value: \"my_pipeline\"\n",
      "                }\n",
      "              }\n",
      "            }\n",
      "            context_queries {\n",
      "              type {\n",
      "                name: \"pipeline_run\"\n",
      "              }\n",
      "              name {\n",
      "                runtime_parameter {\n",
      "                  name: \"pipeline_run_id\"\n",
      "                  type: STRING\n",
      "                }\n",
      "              }\n",
      "            }\n",
      "            context_queries {\n",
      "              type {\n",
      "                name: \"node\"\n",
      "              }\n",
      "              name {\n",
      "                field_value {\n",
      "                  string_value: \"my_pipeline.InfraValidator\"\n",
      "                }\n",
      "              }\n",
      "            }\n",
      "            artifact_query {\n",
      "              type {\n",
      "                name: \"InfraBlessing\"\n",
      "              }\n",
      "            }\n",
      "            output_key: \"blessing\"\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "      inputs {\n",
      "        key: \"model\"\n",
      "        value {\n",
      "          channels {\n",
      "            producer_node_query {\n",
      "              id: \"Trainer\"\n",
      "            }\n",
      "            context_queries {\n",
      "              type {\n",
      "                name: \"pipeline\"\n",
      "              }\n",
      "              name {\n",
      "                field_value {\n",
      "                  string_value: \"my_pipeline\"\n",
      "                }\n",
      "              }\n",
      "            }\n",
      "            context_queries {\n",
      "              type {\n",
      "                name: \"pipeline_run\"\n",
      "              }\n",
      "              name {\n",
      "                runtime_parameter {\n",
      "                  name: \"pipeline_run_id\"\n",
      "                  type: STRING\n",
      "                }\n",
      "              }\n",
      "            }\n",
      "            context_queries {\n",
      "              type {\n",
      "                name: \"node\"\n",
      "              }\n",
      "              name {\n",
      "                field_value {\n",
      "                  string_value: \"my_pipeline.Trainer\"\n",
      "                }\n",
      "              }\n",
      "            }\n",
      "            artifact_query {\n",
      "              type {\n",
      "                name: \"Model\"\n",
      "              }\n",
      "            }\n",
      "            output_key: \"model\"\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "      inputs {\n",
      "        key: \"model_blessing\"\n",
      "        value {\n",
      "          channels {\n",
      "            producer_node_query {\n",
      "              id: \"Evaluator\"\n",
      "            }\n",
      "            context_queries {\n",
      "              type {\n",
      "                name: \"pipeline\"\n",
      "              }\n",
      "              name {\n",
      "                field_value {\n",
      "                  string_value: \"my_pipeline\"\n",
      "                }\n",
      "              }\n",
      "            }\n",
      "            context_queries {\n",
      "              type {\n",
      "                name: \"pipeline_run\"\n",
      "              }\n",
      "              name {\n",
      "                runtime_parameter {\n",
      "                  name: \"pipeline_run_id\"\n",
      "                  type: STRING\n",
      "                }\n",
      "              }\n",
      "            }\n",
      "            context_queries {\n",
      "              type {\n",
      "                name: \"node\"\n",
      "              }\n",
      "              name {\n",
      "                field_value {\n",
      "                  string_value: \"my_pipeline.Evaluator\"\n",
      "                }\n",
      "              }\n",
      "            }\n",
      "            artifact_query {\n",
      "              type {\n",
      "                name: \"ModelBlessing\"\n",
      "              }\n",
      "            }\n",
      "            output_key: \"blessing\"\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "    outputs {\n",
      "      outputs {\n",
      "        key: \"pushed_model\"\n",
      "        value {\n",
      "          artifact_spec {\n",
      "            type {\n",
      "              name: \"PushedModel\"\n",
      "            }\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "    parameters {\n",
      "      parameters {\n",
      "        key: \"custom_config\"\n",
      "        value {\n",
      "          field_value {\n",
      "            string_value: \"null\"\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "      parameters {\n",
      "        key: \"push_destination\"\n",
      "        value {\n",
      "          field_value {\n",
      "            string_value: \"{\\n  \\\"filesystem\\\": {\\n    \\\"base_directory\\\": \\\"gs://gcp-bert-aas-kubeflowpipelines-default/tfx_pipeline_output/my_pipeline/serving_model\\\"\\n  }\\n}\"\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "    upstream_nodes: \"Evaluator\"\n",
      "    upstream_nodes: \"InfraValidator\"\n",
      "    upstream_nodes: \"Trainer\"\n",
      "    execution_options {\n",
      "      caching_options {\n",
      "        enable_cache: true\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "runtime_spec {\n",
      "  pipeline_root {\n",
      "    runtime_parameter {\n",
      "      name: \"pipeline_root\"\n",
      "      type: STRING\n",
      "      default_value {\n",
      "        string_value: \"gs://gcp-bert-aas-kubeflowpipelines-default/tfx_pipeline_output/my_pipeline\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  pipeline_run_id {\n",
      "    runtime_parameter {\n",
      "      name: \"pipeline_run_id\"\n",
      "      type: STRING\n",
      "    }\n",
      "  }\n",
      "}\n",
      "execution_mode: SYNC\n",
      "deployment_config {\n",
      "  type_url: \"type.googleapis.com/tfx.orchestration.IntermediateDeploymentConfig\"\n",
      "  value: \"\\n\\230\\001\\n\\016InfraValidator\\022\\205\\001\\nOtype.googleapis.com/tfx.orchestration.executable_spec.PythonClassExecutableSpec\\0222\\n0tfx.components.infra_validator.executor.Executor\\n\\206\\001\\n\\006Pusher\\022|\\nOtype.googleapis.com/tfx.orchestration.executable_spec.PythonClassExecutableSpec\\022)\\n\\'tfx.components.pusher.executor.Executor\\n\\220\\001\\n\\rStatisticsGen\\022\\177\\nHtype.googleapis.com/tfx.orchestration.executable_spec.BeamExecutableSpec\\0223\\n1\\n/tfx.components.statistics_gen.executor.Executor\\n\\220\\001\\n\\007Trainer\\022\\204\\001\\nOtype.googleapis.com/tfx.orchestration.executable_spec.PythonClassExecutableSpec\\0221\\n/tfx.components.trainer.executor.GenericExecutor\\n\\204\\001\\n\\005Tuner\\022{\\nOtype.googleapis.com/tfx.orchestration.executable_spec.PythonClassExecutableSpec\\022(\\n&tfx.components.tuner.executor.Executor\\n\\207\\001\\n\\tEvaluator\\022z\\nHtype.googleapis.com/tfx.orchestration.executable_spec.BeamExecutableSpec\\022.\\n,\\n*tfx.components.evaluator.executor.Executor\\n\\216\\001\\n\\tSchemaGen\\022\\200\\001\\nOtype.googleapis.com/tfx.orchestration.executable_spec.PythonClassExecutableSpec\\022-\\n+tfx.components.schema_gen.executor.Executor\\n\\234\\001\\n\\020ExampleValidator\\022\\207\\001\\nOtype.googleapis.com/tfx.orchestration.executable_spec.PythonClassExecutableSpec\\0224\\n2tfx.components.example_validator.executor.Executor\\n\\207\\001\\n\\tTransform\\022z\\nHtype.googleapis.com/tfx.orchestration.executable_spec.BeamExecutableSpec\\022.\\n,\\n*tfx.components.transform.executor.Executor\\n\\236\\001\\n\\rCsvExampleGen\\022\\214\\001\\nHtype.googleapis.com/tfx.orchestration.executable_spec.BeamExecutableSpec\\022@\\n>\\n<tfx.components.example_gen.csv_example_gen.executor.Executor\\022\\230\\001\\n\\rCsvExampleGen\\022\\206\\001\\nOtype.googleapis.com/tfx.orchestration.executable_spec.PythonClassExecutableSpec\\0223\\n1tfx.components.example_gen.driver.FileBasedDriver\"\n",
      "}\n",
      "\n",
      "INFO:absl:Adding upstream dependencies for component csvexamplegen\n",
      "INFO:absl:Adding upstream dependencies for component latest-blessed-model-resolver\n",
      "INFO:absl:Adding upstream dependencies for component statisticsgen\n",
      "INFO:absl:   ->  Component: csvexamplegen\n",
      "INFO:absl:Adding upstream dependencies for component schemagen\n",
      "INFO:absl:   ->  Component: statisticsgen\n",
      "INFO:absl:Adding upstream dependencies for component examplevalidator\n",
      "INFO:absl:   ->  Component: schemagen\n",
      "INFO:absl:   ->  Component: statisticsgen\n",
      "INFO:absl:Adding upstream dependencies for component transform\n",
      "INFO:absl:   ->  Component: csvexamplegen\n",
      "INFO:absl:   ->  Component: schemagen\n",
      "INFO:absl:Adding upstream dependencies for component tuner\n",
      "INFO:absl:   ->  Component: transform\n",
      "INFO:absl:Adding upstream dependencies for component trainer\n",
      "INFO:absl:   ->  Component: tuner\n",
      "INFO:absl:   ->  Component: transform\n",
      "INFO:absl:   ->  Component: schemagen\n",
      "INFO:absl:Adding upstream dependencies for component evaluator\n",
      "INFO:absl:   ->  Component: csvexamplegen\n",
      "INFO:absl:   ->  Component: latest-blessed-model-resolver\n",
      "INFO:absl:   ->  Component: trainer\n",
      "INFO:absl:Adding upstream dependencies for component infravalidator\n",
      "INFO:absl:   ->  Component: csvexamplegen\n",
      "INFO:absl:   ->  Component: trainer\n",
      "INFO:absl:Adding upstream dependencies for component pusher\n",
      "INFO:absl:   ->  Component: infravalidator\n",
      "INFO:absl:   ->  Component: trainer\n",
      "INFO:absl:   ->  Component: evaluator\n",
      "Please access the pipeline detail page at http://4c4887d40ceb4e53-dot-us-central1.pipelines.googleusercontent.com/#/pipelines/details/76b7818b-0df8-4b3c-bfc6-c6795c5ef7b6\n",
      "Pipeline \"my_pipeline\" updated successfully.\n",
      "\u001b[0m2021-06-05 20:42:22.266424: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0\n",
      "WARNING:absl:RuntimeParameter is only supported on Cloud-based DAG runner currently.\n",
      "CLI\n",
      "Creating a run for pipeline: my_pipeline\n",
      "Detected Kubeflow.\n",
      "Use --engine flag if you intend to use a different orchestrator.\n",
      "/opt/conda/lib/python3.7/site-packages/kfp/_client.py:182: UserWarning: The host 4c4887d40ceb4e53-dot-us-central1.pipelines.googleusercontent.com does not contain the \"http\" or \"https\" protocol. Defaults to \"https\".\n",
      "  ' Defaults to \"https\".' % host)\n",
      "Run created for pipeline: my_pipeline\n",
      "+===============+======================================+========+===========================+=============================================================================================================================+\n",
      "| pipeline_name | run_id                               | status | created_at                | link                                                                                                                        |\n",
      "+===============+======================================+========+===========================+=============================================================================================================================+\n",
      "| my_pipeline   | 38f75ed7-053e-4a93-97cd-e2c65e713822 | None   | 2021-06-05T20:42:26+00:00 | http://4c4887d40ceb4e53-dot-us-central1.pipelines.googleusercontent.com/#/runs/details/38f75ed7-053e-4a93-97cd-e2c65e713822 |\n",
      "+===============+======================================+========+===========================+=============================================================================================================================+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Update the pipeline\n",
    "!tfx pipeline update \\\n",
    "--pipeline-path=kubeflow_runner.py \\\n",
    "--endpoint={ENDPOINT} \\\n",
    "# --build-image\n",
    "\n",
    "# You can run the pipeline the same way.\n",
    "!tfx run create \\\n",
    "--pipeline-name {PIPELINE_NAME} \\\n",
    "--endpoint={ENDPOINT}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8q1ZYEHX0olo"
   },
   "source": [
    "### Check pipeline outputs\n",
    "\n",
    "Visit the KFP dashboard to find pipeline outputs in the page for your pipeline run. Click the *Experiments* tab on the left, and *All runs* in the Experiments page. You should be able to find the latest run under the name of your pipeline."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dWMBXU510olp"
   },
   "source": [
    "**NOTE:** If we changed anything in the model code, we have to rebuild the\n",
    "container image, too. We can trigger rebuild using `--build-image` flag in the\n",
    "`pipeline update` command.\n",
    "\n",
    "**NOTE:** You might have noticed that every time we create a pipeline run, every component runs again and again even though the input and the parameters were not changed.\n",
    "It is waste of time and resources, and you can skip those executions with pipeline caching. You can enable caching by specifying `enable_cache=True` for the `Pipeline` object in `pipeline.py`.\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "template.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "environment": {
   "name": "tf2-gpu.2-5.m71",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/tf2-gpu.2-5:m71"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
