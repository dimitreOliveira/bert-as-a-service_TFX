{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6TyrY7lV0oke"
   },
   "source": [
    "## BERT as a service\n",
    "\n",
    "This notebook demonstrates how to build a complete machine learning pipeline using TensorFlow Extended ([TFX](https://www.tensorflow.org/tfx)) to serve a BERT model for text sentiment classification.\n",
    "\n",
    "Notes:\n",
    " - Data: IMDB Movie Reviews (5000 samples) [original source](https://ai.stanford.edu/~amaas/data/sentiment/)\n",
    " - Model: BERT base uncased (english) from [HuggingFace](https://huggingface.co/bert-base-uncased)\n",
    " - Processor: BERT uncased (english seq_length=128) from [TF HUB](https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3)\n",
    "\n",
    "\n",
    "You can check references, additional information, and resources at the [GitHub repository](https://github.com/dimitreOliveira/bert-as-a-service_TFX)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "XNiqq_kN0okj"
   },
   "outputs": [],
   "source": [
    "# Kubleflow setup\n",
    "import sys\n",
    "# Use the latest version of pip.\n",
    "!pip install --upgrade -q pip\n",
    "# Install tfx and kfp Python packages.\n",
    "!pip install -q --pre tfx[kfp]==1.0.0rc1\n",
    "\n",
    "# # General setup\n",
    "!pip install -q tensorflow_text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-am1yWXt0okh"
   },
   "source": [
    "### Import packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import os\n",
    "# import json\n",
    "# import absl\n",
    "# import shutil\n",
    "# import pprint\n",
    "import urllib\n",
    "# import tempfile\n",
    "# import requests\n",
    "import tensorflow as tf\n",
    "import tfx\n",
    "# import grpc\n",
    "# import transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Set up logging.\n",
    "# absl.logging.set_verbosity(absl.logging.INFO)\n",
    "\n",
    "# tf.get_logger().propagate = False\n",
    "# pp = pprint.PrettyPrinter()\n",
    "# %load_ext tfx.orchestration.experimental.interactive.notebook_extensions.skip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow version: 2.5.0\n",
      "TFX version: 1.0.0-rc1\n"
     ]
    }
   ],
   "source": [
    "print(f'TensorFlow version: {tf.__version__}')\n",
    "print(f'TFX version: {tfx.__version__}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_7JLpaXT0okv"
   },
   "source": [
    "[Kubeflow Pipelines](https://www.kubeflow.org/docs/pipelines/overview/pipelines-overview/) environment variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "Hw3nsooU0okv"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: GOOGLE_CLOUD_PROJECT=tfx-bert-aas\n",
      "GCP project ID:tfx-bert-aas\n"
     ]
    }
   ],
   "source": [
    "# Read GCP project id from env.\n",
    "shell_output=!gcloud config list --format 'value(core.project)' 2>/dev/null\n",
    "GOOGLE_CLOUD_PROJECT=shell_output[0]\n",
    "%env GOOGLE_CLOUD_PROJECT={GOOGLE_CLOUD_PROJECT}\n",
    "print(\"GCP project ID:\" + GOOGLE_CLOUD_PROJECT)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "A_6r4uzE0oky"
   },
   "source": [
    "KFP endpoint\n",
    "\"AI Platform > Pipeline > pipeline instance `settings`\"\n",
    "**ENDPOINT should contain only the hostname part of the URL.** For example, if the URL of the KFP dashboard is `https://1e9deb537390ca22-dot-asia-east1.pipelines.googleusercontent.com/#/start`, ENDPOINT value becomes `1e9deb537390ca22-dot-asia-east1.pipelines.googleusercontent.com`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "AzqEQORV0oky"
   },
   "outputs": [],
   "source": [
    "# This refers to the KFP cluster endpoint\n",
    "ENDPOINT='3ad82eac8d7dd4b7-dot-us-central1.pipelines.googleusercontent.com'\n",
    "if not ENDPOINT:\n",
    "    from absl import logging\n",
    "    logging.error('Set your ENDPOINT in this cell.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "K6T-KXeA0ok3"
   },
   "source": [
    "Set the image name as `tfx-pipeline` under the current GCP project."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "3ztxXOVD0ok4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gcr.io/tfx-bert-aas/tfx-pipeline\n"
     ]
    }
   ],
   "source": [
    "# Docker image name for the pipeline image.\n",
    "CUSTOM_TFX_IMAGE='gcr.io/' + GOOGLE_CLOUD_PROJECT + '/tfx-pipeline'\n",
    "print(CUSTOM_TFX_IMAGE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Cxlbi1QM0ok8"
   },
   "source": [
    "## Step 2. Copy the predefined template to your project directory.\n",
    "\n",
    "In this step, we will create a working pipeline project directory and files by copying additional files from a predefined template.\n",
    "\n",
    "You may give your pipeline a different name by changing the `PIPELINE_NAME` below. This will also become the name of the project directory where your files will be put."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "cIPlt-700ok-"
   },
   "outputs": [],
   "source": [
    "PIPELINE_NAME=\"my_pipeline\"\n",
    "import os\n",
    "PROJECT_DIR=os.path.join(os.path.expanduser(\"~\"),\"imported\",PIPELINE_NAME)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yxOT19QS0olH"
   },
   "source": [
    "Change the working directory context in this notebook to the project directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "6P-HljcU0olI"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/jupyter/imported/my_pipeline\n"
     ]
    }
   ],
   "source": [
    "%cd {PROJECT_DIR}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IzT2PFrN0olQ"
   },
   "source": [
    "## Source files\n",
    "\n",
    "Here is brief introduction to each of the Python files.\n",
    "-   `data` - This directory contains the datasets.\n",
    "-   `models` - This directory contains ML model definitions.\n",
    "    -   `bert_aas_utils.py` — defines utility functions for the pipeline\n",
    "-   `pipeline` - This directory contains the definition of the pipeline\n",
    "    -   `configs.py` — defines common constants for pipeline runners\n",
    "    -   `pipeline.py` — defines TFX components and a pipeline\n",
    "-   `local_runner.py`, `kubeflow_runner.py` — define runners for each orchestration engine\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Download data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_csv_url = 'https://raw.githubusercontent.com/dimitreOliveira/bert-as-a-service_TFX/main/Data/IMDB_5k_dataset.csv'\n",
    "# data_txt_url = 'https://raw.githubusercontent.com/dimitreOliveira/bert-as-a-service_TFX/main/Data/IMDB_5k_dataset.csv'\n",
    "data_csv_filename = 'IMDB_dataset.csv'\n",
    "# data_txt_filename = 'IMDB_dataset.txt'\n",
    "\n",
    "_data_dir = 'data/'\n",
    "\n",
    "# Download data\n",
    "urllib.request.urlretrieve(data_csv_url, f'{_data_dir}{data_csv_filename}')\n",
    "# urllib.request.urlretrieve(data_txt_url, f'{_data_dir}{data_txt_filename}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Upload our sample data to GCS bucket so that we can use it in our pipeline later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!gsutil cp data/IMDB_dataset.csv gs://{GOOGLE_CLOUD_PROJECT}-kubeflowpipelines-default/bert-aas/data/IMDB_dataset.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tO9Jhplo0olX"
   },
   "source": [
    "## Create TFX pipeline\n",
    "\n",
    "Components in the TFX pipeline will generate outputs for each run as [ML Metadata Artifacts](https://www.tensorflow.org/tfx/guide/mlmd), and they need to be stored somewhere. You can use any storage which the KFP cluster can access, and for this example we will use Google Cloud Storage (GCS). A default GCS bucket should have been created automatically. Its name will be `<your-project-id>-kubeflowpipelines-default`.\n",
    "\n",
    "Let's create a TFX pipeline using the `tfx pipeline create` command.\n",
    "\n",
    ">Note: When creating a pipeline for KFP, we need a container image which will be used to run our pipeline. And `skaffold` will build the image for us. Because skaffold pulls base images from the docker hub, it will take 5~10 minutes when we build the image for the first time, but it will take much less time from the second build."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "kOU7zQof0olf"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:absl:RuntimeParameter is only supported on Cloud-based DAG runner currently.\n",
      "CLI\n",
      "Creating pipeline\n",
      "Detected Kubeflow.\n",
      "Use --engine flag if you intend to use a different orchestrator.\n",
      "/opt/conda/lib/python3.7/site-packages/kfp/_client.py:182: UserWarning: The host 3ad82eac8d7dd4b7-dot-us-central1.pipelines.googleusercontent.com does not contain the \"http\" or \"https\" protocol. Defaults to \"https\".\n",
      "  ' Defaults to \"https\".' % host)\n",
      "INFO:absl:Excluding no splits because exclude_splits is not set.\n",
      "INFO:absl:Excluding no splits because exclude_splits is not set.\n",
      "INFO:absl:Excluding no splits because exclude_splits is not set.\n",
      "[Docker] Step 1/4 : FROM tensorflow/tfx:1.0.0-rc1[Docker] \n",
      "[Docker] The push refers to repository [gcr.io/tfx-bert-aas/my_pipeline]\n",
      "New container image \"gcr.io/tfx-bert-aas/my_pipeline@sha256:a040ebe64479b934e919395dc6fbc3d353293643a696381d37f8585c6eed85cd\" was built.\n",
      "INFO:absl:Generating ephemeral wheel package for '/home/jupyter/imported/my_pipeline/pipeline/bert_aas_utils.py' (including modules: ['bert_aas_utils', 'configs', 'pipeline']).\n",
      "INFO:absl:User module package has hash fingerprint version ae8c7ab9ebdf3b0d138ed4c3226e39b06c47cf35ea403193e9e1be074d7eeb2d.\n",
      "INFO:absl:Executing: ['/opt/conda/bin/python3.7', '/tmp/tmpowgt7xt6/_tfx_generated_setup.py', 'bdist_wheel', '--bdist-dir', '/tmp/tmpg1j8xt6g', '--dist-dir', '/tmp/tmp3y6ighy3']\n",
      "running bdist_wheel\n",
      "running build\n",
      "running build_py\n",
      "creating build\n",
      "creating build/lib\n",
      "copying bert_aas_utils.py -> build/lib\n",
      "copying configs.py -> build/lib\n",
      "copying pipeline.py -> build/lib\n",
      "installing to /tmp/tmpg1j8xt6g\n",
      "running install\n",
      "running install_lib\n",
      "copying build/lib/configs.py -> /tmp/tmpg1j8xt6g\n",
      "copying build/lib/pipeline.py -> /tmp/tmpg1j8xt6g\n",
      "copying build/lib/bert_aas_utils.py -> /tmp/tmpg1j8xt6g\n",
      "running install_egg_info\n",
      "running egg_info\n",
      "creating tfx_user_code_Transform.egg-info\n",
      "writing tfx_user_code_Transform.egg-info/PKG-INFO\n",
      "writing dependency_links to tfx_user_code_Transform.egg-info/dependency_links.txt\n",
      "writing top-level names to tfx_user_code_Transform.egg-info/top_level.txt\n",
      "writing manifest file 'tfx_user_code_Transform.egg-info/SOURCES.txt'\n",
      "reading manifest file 'tfx_user_code_Transform.egg-info/SOURCES.txt'\n",
      "writing manifest file 'tfx_user_code_Transform.egg-info/SOURCES.txt'\n",
      "Copying tfx_user_code_Transform.egg-info to /tmp/tmpg1j8xt6g/tfx_user_code_Transform-0.0+ae8c7ab9ebdf3b0d138ed4c3226e39b06c47cf35ea403193e9e1be074d7eeb2d-py3.7.egg-info\n",
      "running install_scripts\n",
      "creating /tmp/tmpg1j8xt6g/tfx_user_code_Transform-0.0+ae8c7ab9ebdf3b0d138ed4c3226e39b06c47cf35ea403193e9e1be074d7eeb2d.dist-info/WHEEL\n",
      "creating '/tmp/tmp3y6ighy3/tfx_user_code_Transform-0.0+ae8c7ab9ebdf3b0d138ed4c3226e39b06c47cf35ea403193e9e1be074d7eeb2d-py3-none-any.whl' and adding '/tmp/tmpg1j8xt6g' to it\n",
      "adding 'bert_aas_utils.py'\n",
      "adding 'configs.py'\n",
      "adding 'pipeline.py'\n",
      "adding 'tfx_user_code_Transform-0.0+ae8c7ab9ebdf3b0d138ed4c3226e39b06c47cf35ea403193e9e1be074d7eeb2d.dist-info/METADATA'\n",
      "adding 'tfx_user_code_Transform-0.0+ae8c7ab9ebdf3b0d138ed4c3226e39b06c47cf35ea403193e9e1be074d7eeb2d.dist-info/WHEEL'\n",
      "adding 'tfx_user_code_Transform-0.0+ae8c7ab9ebdf3b0d138ed4c3226e39b06c47cf35ea403193e9e1be074d7eeb2d.dist-info/top_level.txt'\n",
      "adding 'tfx_user_code_Transform-0.0+ae8c7ab9ebdf3b0d138ed4c3226e39b06c47cf35ea403193e9e1be074d7eeb2d.dist-info/RECORD'\n",
      "removing /tmp/tmpg1j8xt6g\n",
      "INFO:absl:Successfully built user code wheel distribution at 'gs://tfx-bert-aas-kubeflowpipelines-default/tfx_pipeline_output/my_pipeline/_wheels/tfx_user_code_Transform-0.0+ae8c7ab9ebdf3b0d138ed4c3226e39b06c47cf35ea403193e9e1be074d7eeb2d-py3-none-any.whl'; target user module is 'bert_aas_utils'.\n",
      "INFO:absl:Full user module path is 'bert_aas_utils@gs://tfx-bert-aas-kubeflowpipelines-default/tfx_pipeline_output/my_pipeline/_wheels/tfx_user_code_Transform-0.0+ae8c7ab9ebdf3b0d138ed4c3226e39b06c47cf35ea403193e9e1be074d7eeb2d-py3-none-any.whl'\n",
      "INFO:absl:Generating ephemeral wheel package for '/home/jupyter/imported/my_pipeline/pipeline/bert_aas_utils.py' (including modules: ['bert_aas_utils', 'configs', 'pipeline']).\n",
      "INFO:absl:User module package has hash fingerprint version ae8c7ab9ebdf3b0d138ed4c3226e39b06c47cf35ea403193e9e1be074d7eeb2d.\n",
      "INFO:absl:Executing: ['/opt/conda/bin/python3.7', '/tmp/tmphn7drhlv/_tfx_generated_setup.py', 'bdist_wheel', '--bdist-dir', '/tmp/tmp1rkvsbmz', '--dist-dir', '/tmp/tmpmiq4nh3w']\n",
      "running bdist_wheel\n",
      "running build\n",
      "running build_py\n",
      "creating build\n",
      "creating build/lib\n",
      "copying bert_aas_utils.py -> build/lib\n",
      "copying configs.py -> build/lib\n",
      "copying pipeline.py -> build/lib\n",
      "installing to /tmp/tmp1rkvsbmz\n",
      "running install\n",
      "running install_lib\n",
      "copying build/lib/configs.py -> /tmp/tmp1rkvsbmz\n",
      "copying build/lib/pipeline.py -> /tmp/tmp1rkvsbmz\n",
      "copying build/lib/bert_aas_utils.py -> /tmp/tmp1rkvsbmz\n",
      "running install_egg_info\n",
      "running egg_info\n",
      "creating tfx_user_code_Tuner.egg-info\n",
      "writing tfx_user_code_Tuner.egg-info/PKG-INFO\n",
      "writing dependency_links to tfx_user_code_Tuner.egg-info/dependency_links.txt\n",
      "writing top-level names to tfx_user_code_Tuner.egg-info/top_level.txt\n",
      "writing manifest file 'tfx_user_code_Tuner.egg-info/SOURCES.txt'\n",
      "reading manifest file 'tfx_user_code_Tuner.egg-info/SOURCES.txt'\n",
      "writing manifest file 'tfx_user_code_Tuner.egg-info/SOURCES.txt'\n",
      "Copying tfx_user_code_Tuner.egg-info to /tmp/tmp1rkvsbmz/tfx_user_code_Tuner-0.0+ae8c7ab9ebdf3b0d138ed4c3226e39b06c47cf35ea403193e9e1be074d7eeb2d-py3.7.egg-info\n",
      "running install_scripts\n",
      "creating /tmp/tmp1rkvsbmz/tfx_user_code_Tuner-0.0+ae8c7ab9ebdf3b0d138ed4c3226e39b06c47cf35ea403193e9e1be074d7eeb2d.dist-info/WHEEL\n",
      "creating '/tmp/tmpmiq4nh3w/tfx_user_code_Tuner-0.0+ae8c7ab9ebdf3b0d138ed4c3226e39b06c47cf35ea403193e9e1be074d7eeb2d-py3-none-any.whl' and adding '/tmp/tmp1rkvsbmz' to it\n",
      "adding 'bert_aas_utils.py'\n",
      "adding 'configs.py'\n",
      "adding 'pipeline.py'\n",
      "adding 'tfx_user_code_Tuner-0.0+ae8c7ab9ebdf3b0d138ed4c3226e39b06c47cf35ea403193e9e1be074d7eeb2d.dist-info/METADATA'\n",
      "adding 'tfx_user_code_Tuner-0.0+ae8c7ab9ebdf3b0d138ed4c3226e39b06c47cf35ea403193e9e1be074d7eeb2d.dist-info/WHEEL'\n",
      "adding 'tfx_user_code_Tuner-0.0+ae8c7ab9ebdf3b0d138ed4c3226e39b06c47cf35ea403193e9e1be074d7eeb2d.dist-info/top_level.txt'\n",
      "adding 'tfx_user_code_Tuner-0.0+ae8c7ab9ebdf3b0d138ed4c3226e39b06c47cf35ea403193e9e1be074d7eeb2d.dist-info/RECORD'\n",
      "removing /tmp/tmp1rkvsbmz\n",
      "INFO:absl:Successfully built user code wheel distribution at 'gs://tfx-bert-aas-kubeflowpipelines-default/tfx_pipeline_output/my_pipeline/_wheels/tfx_user_code_Tuner-0.0+ae8c7ab9ebdf3b0d138ed4c3226e39b06c47cf35ea403193e9e1be074d7eeb2d-py3-none-any.whl'; target user module is 'bert_aas_utils'.\n",
      "INFO:absl:Full user module path is 'bert_aas_utils@gs://tfx-bert-aas-kubeflowpipelines-default/tfx_pipeline_output/my_pipeline/_wheels/tfx_user_code_Tuner-0.0+ae8c7ab9ebdf3b0d138ed4c3226e39b06c47cf35ea403193e9e1be074d7eeb2d-py3-none-any.whl'\n",
      "INFO:absl:Generated pipeline:\n",
      " pipeline_info {\n",
      "  id: \"my_pipeline\"\n",
      "}\n",
      "nodes {\n",
      "  pipeline_node {\n",
      "    node_info {\n",
      "      type {\n",
      "        name: \"tfx.components.example_gen.csv_example_gen.component.CsvExampleGen\"\n",
      "      }\n",
      "      id: \"CsvExampleGen\"\n",
      "    }\n",
      "    contexts {\n",
      "      contexts {\n",
      "        type {\n",
      "          name: \"pipeline\"\n",
      "        }\n",
      "        name {\n",
      "          field_value {\n",
      "            string_value: \"my_pipeline\"\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "      contexts {\n",
      "        type {\n",
      "          name: \"pipeline_run\"\n",
      "        }\n",
      "        name {\n",
      "          runtime_parameter {\n",
      "            name: \"pipeline_run_id\"\n",
      "            type: STRING\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "      contexts {\n",
      "        type {\n",
      "          name: \"node\"\n",
      "        }\n",
      "        name {\n",
      "          field_value {\n",
      "            string_value: \"my_pipeline.CsvExampleGen\"\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "    outputs {\n",
      "      outputs {\n",
      "        key: \"examples\"\n",
      "        value {\n",
      "          artifact_spec {\n",
      "            type {\n",
      "              name: \"Examples\"\n",
      "              properties {\n",
      "                key: \"span\"\n",
      "                value: INT\n",
      "              }\n",
      "              properties {\n",
      "                key: \"split_names\"\n",
      "                value: STRING\n",
      "              }\n",
      "              properties {\n",
      "                key: \"version\"\n",
      "                value: INT\n",
      "              }\n",
      "            }\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "    parameters {\n",
      "      parameters {\n",
      "        key: \"input_base\"\n",
      "        value {\n",
      "          field_value {\n",
      "            string_value: \"gs://tfx-bert-aas-kubeflowpipelines-default/bert-aas/data/\"\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "      parameters {\n",
      "        key: \"input_config\"\n",
      "        value {\n",
      "          field_value {\n",
      "            string_value: \"{\\n  \\\"splits\\\": [\\n    {\\n      \\\"name\\\": \\\"single_split\\\",\\n      \\\"pattern\\\": \\\"*\\\"\\n    }\\n  ]\\n}\"\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "      parameters {\n",
      "        key: \"output_config\"\n",
      "        value {\n",
      "          field_value {\n",
      "            string_value: \"{\\n  \\\"split_config\\\": {\\n    \\\"splits\\\": [\\n      {\\n        \\\"hash_buckets\\\": 4,\\n        \\\"name\\\": \\\"train\\\"\\n      },\\n      {\\n        \\\"hash_buckets\\\": 1,\\n        \\\"name\\\": \\\"eval\\\"\\n      }\\n    ]\\n  }\\n}\"\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "      parameters {\n",
      "        key: \"output_data_format\"\n",
      "        value {\n",
      "          field_value {\n",
      "            int_value: 6\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "    downstream_nodes: \"StatisticsGen\"\n",
      "    downstream_nodes: \"Transform\"\n",
      "    execution_options {\n",
      "      caching_options {\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "nodes {\n",
      "  pipeline_node {\n",
      "    node_info {\n",
      "      type {\n",
      "        name: \"tfx.components.statistics_gen.component.StatisticsGen\"\n",
      "      }\n",
      "      id: \"StatisticsGen\"\n",
      "    }\n",
      "    contexts {\n",
      "      contexts {\n",
      "        type {\n",
      "          name: \"pipeline\"\n",
      "        }\n",
      "        name {\n",
      "          field_value {\n",
      "            string_value: \"my_pipeline\"\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "      contexts {\n",
      "        type {\n",
      "          name: \"pipeline_run\"\n",
      "        }\n",
      "        name {\n",
      "          runtime_parameter {\n",
      "            name: \"pipeline_run_id\"\n",
      "            type: STRING\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "      contexts {\n",
      "        type {\n",
      "          name: \"node\"\n",
      "        }\n",
      "        name {\n",
      "          field_value {\n",
      "            string_value: \"my_pipeline.StatisticsGen\"\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "    inputs {\n",
      "      inputs {\n",
      "        key: \"examples\"\n",
      "        value {\n",
      "          channels {\n",
      "            producer_node_query {\n",
      "              id: \"CsvExampleGen\"\n",
      "            }\n",
      "            context_queries {\n",
      "              type {\n",
      "                name: \"pipeline\"\n",
      "              }\n",
      "              name {\n",
      "                field_value {\n",
      "                  string_value: \"my_pipeline\"\n",
      "                }\n",
      "              }\n",
      "            }\n",
      "            context_queries {\n",
      "              type {\n",
      "                name: \"pipeline_run\"\n",
      "              }\n",
      "              name {\n",
      "                runtime_parameter {\n",
      "                  name: \"pipeline_run_id\"\n",
      "                  type: STRING\n",
      "                }\n",
      "              }\n",
      "            }\n",
      "            context_queries {\n",
      "              type {\n",
      "                name: \"node\"\n",
      "              }\n",
      "              name {\n",
      "                field_value {\n",
      "                  string_value: \"my_pipeline.CsvExampleGen\"\n",
      "                }\n",
      "              }\n",
      "            }\n",
      "            artifact_query {\n",
      "              type {\n",
      "                name: \"Examples\"\n",
      "              }\n",
      "            }\n",
      "            output_key: \"examples\"\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "    outputs {\n",
      "      outputs {\n",
      "        key: \"statistics\"\n",
      "        value {\n",
      "          artifact_spec {\n",
      "            type {\n",
      "              name: \"ExampleStatistics\"\n",
      "              properties {\n",
      "                key: \"span\"\n",
      "                value: INT\n",
      "              }\n",
      "              properties {\n",
      "                key: \"split_names\"\n",
      "                value: STRING\n",
      "              }\n",
      "            }\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "    parameters {\n",
      "      parameters {\n",
      "        key: \"exclude_splits\"\n",
      "        value {\n",
      "          field_value {\n",
      "            string_value: \"[]\"\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "    upstream_nodes: \"CsvExampleGen\"\n",
      "    downstream_nodes: \"ExampleValidator\"\n",
      "    downstream_nodes: \"SchemaGen\"\n",
      "    execution_options {\n",
      "      caching_options {\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "nodes {\n",
      "  pipeline_node {\n",
      "    node_info {\n",
      "      type {\n",
      "        name: \"tfx.components.schema_gen.component.SchemaGen\"\n",
      "      }\n",
      "      id: \"SchemaGen\"\n",
      "    }\n",
      "    contexts {\n",
      "      contexts {\n",
      "        type {\n",
      "          name: \"pipeline\"\n",
      "        }\n",
      "        name {\n",
      "          field_value {\n",
      "            string_value: \"my_pipeline\"\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "      contexts {\n",
      "        type {\n",
      "          name: \"pipeline_run\"\n",
      "        }\n",
      "        name {\n",
      "          runtime_parameter {\n",
      "            name: \"pipeline_run_id\"\n",
      "            type: STRING\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "      contexts {\n",
      "        type {\n",
      "          name: \"node\"\n",
      "        }\n",
      "        name {\n",
      "          field_value {\n",
      "            string_value: \"my_pipeline.SchemaGen\"\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "    inputs {\n",
      "      inputs {\n",
      "        key: \"statistics\"\n",
      "        value {\n",
      "          channels {\n",
      "            producer_node_query {\n",
      "              id: \"StatisticsGen\"\n",
      "            }\n",
      "            context_queries {\n",
      "              type {\n",
      "                name: \"pipeline\"\n",
      "              }\n",
      "              name {\n",
      "                field_value {\n",
      "                  string_value: \"my_pipeline\"\n",
      "                }\n",
      "              }\n",
      "            }\n",
      "            context_queries {\n",
      "              type {\n",
      "                name: \"pipeline_run\"\n",
      "              }\n",
      "              name {\n",
      "                runtime_parameter {\n",
      "                  name: \"pipeline_run_id\"\n",
      "                  type: STRING\n",
      "                }\n",
      "              }\n",
      "            }\n",
      "            context_queries {\n",
      "              type {\n",
      "                name: \"node\"\n",
      "              }\n",
      "              name {\n",
      "                field_value {\n",
      "                  string_value: \"my_pipeline.StatisticsGen\"\n",
      "                }\n",
      "              }\n",
      "            }\n",
      "            artifact_query {\n",
      "              type {\n",
      "                name: \"ExampleStatistics\"\n",
      "              }\n",
      "            }\n",
      "            output_key: \"statistics\"\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "    outputs {\n",
      "      outputs {\n",
      "        key: \"schema\"\n",
      "        value {\n",
      "          artifact_spec {\n",
      "            type {\n",
      "              name: \"Schema\"\n",
      "            }\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "    parameters {\n",
      "      parameters {\n",
      "        key: \"exclude_splits\"\n",
      "        value {\n",
      "          field_value {\n",
      "            string_value: \"[]\"\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "      parameters {\n",
      "        key: \"infer_feature_shape\"\n",
      "        value {\n",
      "          field_value {\n",
      "            int_value: 1\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "    upstream_nodes: \"StatisticsGen\"\n",
      "    downstream_nodes: \"ExampleValidator\"\n",
      "    downstream_nodes: \"Transform\"\n",
      "    execution_options {\n",
      "      caching_options {\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "nodes {\n",
      "  pipeline_node {\n",
      "    node_info {\n",
      "      type {\n",
      "        name: \"tfx.components.example_validator.component.ExampleValidator\"\n",
      "      }\n",
      "      id: \"ExampleValidator\"\n",
      "    }\n",
      "    contexts {\n",
      "      contexts {\n",
      "        type {\n",
      "          name: \"pipeline\"\n",
      "        }\n",
      "        name {\n",
      "          field_value {\n",
      "            string_value: \"my_pipeline\"\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "      contexts {\n",
      "        type {\n",
      "          name: \"pipeline_run\"\n",
      "        }\n",
      "        name {\n",
      "          runtime_parameter {\n",
      "            name: \"pipeline_run_id\"\n",
      "            type: STRING\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "      contexts {\n",
      "        type {\n",
      "          name: \"node\"\n",
      "        }\n",
      "        name {\n",
      "          field_value {\n",
      "            string_value: \"my_pipeline.ExampleValidator\"\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "    inputs {\n",
      "      inputs {\n",
      "        key: \"schema\"\n",
      "        value {\n",
      "          channels {\n",
      "            producer_node_query {\n",
      "              id: \"SchemaGen\"\n",
      "            }\n",
      "            context_queries {\n",
      "              type {\n",
      "                name: \"pipeline\"\n",
      "              }\n",
      "              name {\n",
      "                field_value {\n",
      "                  string_value: \"my_pipeline\"\n",
      "                }\n",
      "              }\n",
      "            }\n",
      "            context_queries {\n",
      "              type {\n",
      "                name: \"pipeline_run\"\n",
      "              }\n",
      "              name {\n",
      "                runtime_parameter {\n",
      "                  name: \"pipeline_run_id\"\n",
      "                  type: STRING\n",
      "                }\n",
      "              }\n",
      "            }\n",
      "            context_queries {\n",
      "              type {\n",
      "                name: \"node\"\n",
      "              }\n",
      "              name {\n",
      "                field_value {\n",
      "                  string_value: \"my_pipeline.SchemaGen\"\n",
      "                }\n",
      "              }\n",
      "            }\n",
      "            artifact_query {\n",
      "              type {\n",
      "                name: \"Schema\"\n",
      "              }\n",
      "            }\n",
      "            output_key: \"schema\"\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "      inputs {\n",
      "        key: \"statistics\"\n",
      "        value {\n",
      "          channels {\n",
      "            producer_node_query {\n",
      "              id: \"StatisticsGen\"\n",
      "            }\n",
      "            context_queries {\n",
      "              type {\n",
      "                name: \"pipeline\"\n",
      "              }\n",
      "              name {\n",
      "                field_value {\n",
      "                  string_value: \"my_pipeline\"\n",
      "                }\n",
      "              }\n",
      "            }\n",
      "            context_queries {\n",
      "              type {\n",
      "                name: \"pipeline_run\"\n",
      "              }\n",
      "              name {\n",
      "                runtime_parameter {\n",
      "                  name: \"pipeline_run_id\"\n",
      "                  type: STRING\n",
      "                }\n",
      "              }\n",
      "            }\n",
      "            context_queries {\n",
      "              type {\n",
      "                name: \"node\"\n",
      "              }\n",
      "              name {\n",
      "                field_value {\n",
      "                  string_value: \"my_pipeline.StatisticsGen\"\n",
      "                }\n",
      "              }\n",
      "            }\n",
      "            artifact_query {\n",
      "              type {\n",
      "                name: \"ExampleStatistics\"\n",
      "              }\n",
      "            }\n",
      "            output_key: \"statistics\"\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "    outputs {\n",
      "      outputs {\n",
      "        key: \"anomalies\"\n",
      "        value {\n",
      "          artifact_spec {\n",
      "            type {\n",
      "              name: \"ExampleAnomalies\"\n",
      "              properties {\n",
      "                key: \"span\"\n",
      "                value: INT\n",
      "              }\n",
      "              properties {\n",
      "                key: \"split_names\"\n",
      "                value: STRING\n",
      "              }\n",
      "            }\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "    parameters {\n",
      "      parameters {\n",
      "        key: \"exclude_splits\"\n",
      "        value {\n",
      "          field_value {\n",
      "            string_value: \"[]\"\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "    upstream_nodes: \"SchemaGen\"\n",
      "    upstream_nodes: \"StatisticsGen\"\n",
      "    execution_options {\n",
      "      caching_options {\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "nodes {\n",
      "  pipeline_node {\n",
      "    node_info {\n",
      "      type {\n",
      "        name: \"tfx.components.transform.component.Transform\"\n",
      "      }\n",
      "      id: \"Transform\"\n",
      "    }\n",
      "    contexts {\n",
      "      contexts {\n",
      "        type {\n",
      "          name: \"pipeline\"\n",
      "        }\n",
      "        name {\n",
      "          field_value {\n",
      "            string_value: \"my_pipeline\"\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "      contexts {\n",
      "        type {\n",
      "          name: \"pipeline_run\"\n",
      "        }\n",
      "        name {\n",
      "          runtime_parameter {\n",
      "            name: \"pipeline_run_id\"\n",
      "            type: STRING\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "      contexts {\n",
      "        type {\n",
      "          name: \"node\"\n",
      "        }\n",
      "        name {\n",
      "          field_value {\n",
      "            string_value: \"my_pipeline.Transform\"\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "    inputs {\n",
      "      inputs {\n",
      "        key: \"examples\"\n",
      "        value {\n",
      "          channels {\n",
      "            producer_node_query {\n",
      "              id: \"CsvExampleGen\"\n",
      "            }\n",
      "            context_queries {\n",
      "              type {\n",
      "                name: \"pipeline\"\n",
      "              }\n",
      "              name {\n",
      "                field_value {\n",
      "                  string_value: \"my_pipeline\"\n",
      "                }\n",
      "              }\n",
      "            }\n",
      "            context_queries {\n",
      "              type {\n",
      "                name: \"pipeline_run\"\n",
      "              }\n",
      "              name {\n",
      "                runtime_parameter {\n",
      "                  name: \"pipeline_run_id\"\n",
      "                  type: STRING\n",
      "                }\n",
      "              }\n",
      "            }\n",
      "            context_queries {\n",
      "              type {\n",
      "                name: \"node\"\n",
      "              }\n",
      "              name {\n",
      "                field_value {\n",
      "                  string_value: \"my_pipeline.CsvExampleGen\"\n",
      "                }\n",
      "              }\n",
      "            }\n",
      "            artifact_query {\n",
      "              type {\n",
      "                name: \"Examples\"\n",
      "              }\n",
      "            }\n",
      "            output_key: \"examples\"\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "      inputs {\n",
      "        key: \"schema\"\n",
      "        value {\n",
      "          channels {\n",
      "            producer_node_query {\n",
      "              id: \"SchemaGen\"\n",
      "            }\n",
      "            context_queries {\n",
      "              type {\n",
      "                name: \"pipeline\"\n",
      "              }\n",
      "              name {\n",
      "                field_value {\n",
      "                  string_value: \"my_pipeline\"\n",
      "                }\n",
      "              }\n",
      "            }\n",
      "            context_queries {\n",
      "              type {\n",
      "                name: \"pipeline_run\"\n",
      "              }\n",
      "              name {\n",
      "                runtime_parameter {\n",
      "                  name: \"pipeline_run_id\"\n",
      "                  type: STRING\n",
      "                }\n",
      "              }\n",
      "            }\n",
      "            context_queries {\n",
      "              type {\n",
      "                name: \"node\"\n",
      "              }\n",
      "              name {\n",
      "                field_value {\n",
      "                  string_value: \"my_pipeline.SchemaGen\"\n",
      "                }\n",
      "              }\n",
      "            }\n",
      "            artifact_query {\n",
      "              type {\n",
      "                name: \"Schema\"\n",
      "              }\n",
      "            }\n",
      "            output_key: \"schema\"\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "    outputs {\n",
      "      outputs {\n",
      "        key: \"post_transform_anomalies\"\n",
      "        value {\n",
      "          artifact_spec {\n",
      "            type {\n",
      "              name: \"ExampleAnomalies\"\n",
      "              properties {\n",
      "                key: \"span\"\n",
      "                value: INT\n",
      "              }\n",
      "              properties {\n",
      "                key: \"split_names\"\n",
      "                value: STRING\n",
      "              }\n",
      "            }\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "      outputs {\n",
      "        key: \"post_transform_schema\"\n",
      "        value {\n",
      "          artifact_spec {\n",
      "            type {\n",
      "              name: \"Schema\"\n",
      "            }\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "      outputs {\n",
      "        key: \"post_transform_stats\"\n",
      "        value {\n",
      "          artifact_spec {\n",
      "            type {\n",
      "              name: \"ExampleStatistics\"\n",
      "              properties {\n",
      "                key: \"span\"\n",
      "                value: INT\n",
      "              }\n",
      "              properties {\n",
      "                key: \"split_names\"\n",
      "                value: STRING\n",
      "              }\n",
      "            }\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "      outputs {\n",
      "        key: \"pre_transform_schema\"\n",
      "        value {\n",
      "          artifact_spec {\n",
      "            type {\n",
      "              name: \"Schema\"\n",
      "            }\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "      outputs {\n",
      "        key: \"pre_transform_stats\"\n",
      "        value {\n",
      "          artifact_spec {\n",
      "            type {\n",
      "              name: \"ExampleStatistics\"\n",
      "              properties {\n",
      "                key: \"span\"\n",
      "                value: INT\n",
      "              }\n",
      "              properties {\n",
      "                key: \"split_names\"\n",
      "                value: STRING\n",
      "              }\n",
      "            }\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "      outputs {\n",
      "        key: \"transform_graph\"\n",
      "        value {\n",
      "          artifact_spec {\n",
      "            type {\n",
      "              name: \"TransformGraph\"\n",
      "            }\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "      outputs {\n",
      "        key: \"transformed_examples\"\n",
      "        value {\n",
      "          artifact_spec {\n",
      "            type {\n",
      "              name: \"Examples\"\n",
      "              properties {\n",
      "                key: \"span\"\n",
      "                value: INT\n",
      "              }\n",
      "              properties {\n",
      "                key: \"split_names\"\n",
      "                value: STRING\n",
      "              }\n",
      "              properties {\n",
      "                key: \"version\"\n",
      "                value: INT\n",
      "              }\n",
      "            }\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "      outputs {\n",
      "        key: \"updated_analyzer_cache\"\n",
      "        value {\n",
      "          artifact_spec {\n",
      "            type {\n",
      "              name: \"TransformCache\"\n",
      "            }\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "    parameters {\n",
      "      parameters {\n",
      "        key: \"custom_config\"\n",
      "        value {\n",
      "          field_value {\n",
      "            string_value: \"null\"\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "      parameters {\n",
      "        key: \"disable_statistics\"\n",
      "        value {\n",
      "          field_value {\n",
      "            int_value: 0\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "      parameters {\n",
      "        key: \"force_tf_compat_v1\"\n",
      "        value {\n",
      "          field_value {\n",
      "            int_value: 0\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "      parameters {\n",
      "        key: \"module_path\"\n",
      "        value {\n",
      "          field_value {\n",
      "            string_value: \"bert_aas_utils@gs://tfx-bert-aas-kubeflowpipelines-default/tfx_pipeline_output/my_pipeline/_wheels/tfx_user_code_Transform-0.0+ae8c7ab9ebdf3b0d138ed4c3226e39b06c47cf35ea403193e9e1be074d7eeb2d-py3-none-any.whl\"\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "    upstream_nodes: \"CsvExampleGen\"\n",
      "    upstream_nodes: \"SchemaGen\"\n",
      "    downstream_nodes: \"Tuner\"\n",
      "    execution_options {\n",
      "      caching_options {\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "nodes {\n",
      "  pipeline_node {\n",
      "    node_info {\n",
      "      type {\n",
      "        name: \"tfx.components.tuner.component.Tuner\"\n",
      "      }\n",
      "      id: \"Tuner\"\n",
      "    }\n",
      "    contexts {\n",
      "      contexts {\n",
      "        type {\n",
      "          name: \"pipeline\"\n",
      "        }\n",
      "        name {\n",
      "          field_value {\n",
      "            string_value: \"my_pipeline\"\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "      contexts {\n",
      "        type {\n",
      "          name: \"pipeline_run\"\n",
      "        }\n",
      "        name {\n",
      "          runtime_parameter {\n",
      "            name: \"pipeline_run_id\"\n",
      "            type: STRING\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "      contexts {\n",
      "        type {\n",
      "          name: \"node\"\n",
      "        }\n",
      "        name {\n",
      "          field_value {\n",
      "            string_value: \"my_pipeline.Tuner\"\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "    inputs {\n",
      "      inputs {\n",
      "        key: \"examples\"\n",
      "        value {\n",
      "          channels {\n",
      "            producer_node_query {\n",
      "              id: \"Transform\"\n",
      "            }\n",
      "            context_queries {\n",
      "              type {\n",
      "                name: \"pipeline\"\n",
      "              }\n",
      "              name {\n",
      "                field_value {\n",
      "                  string_value: \"my_pipeline\"\n",
      "                }\n",
      "              }\n",
      "            }\n",
      "            context_queries {\n",
      "              type {\n",
      "                name: \"pipeline_run\"\n",
      "              }\n",
      "              name {\n",
      "                runtime_parameter {\n",
      "                  name: \"pipeline_run_id\"\n",
      "                  type: STRING\n",
      "                }\n",
      "              }\n",
      "            }\n",
      "            context_queries {\n",
      "              type {\n",
      "                name: \"node\"\n",
      "              }\n",
      "              name {\n",
      "                field_value {\n",
      "                  string_value: \"my_pipeline.Transform\"\n",
      "                }\n",
      "              }\n",
      "            }\n",
      "            artifact_query {\n",
      "              type {\n",
      "                name: \"Examples\"\n",
      "              }\n",
      "            }\n",
      "            output_key: \"transformed_examples\"\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "      inputs {\n",
      "        key: \"transform_graph\"\n",
      "        value {\n",
      "          channels {\n",
      "            producer_node_query {\n",
      "              id: \"Transform\"\n",
      "            }\n",
      "            context_queries {\n",
      "              type {\n",
      "                name: \"pipeline\"\n",
      "              }\n",
      "              name {\n",
      "                field_value {\n",
      "                  string_value: \"my_pipeline\"\n",
      "                }\n",
      "              }\n",
      "            }\n",
      "            context_queries {\n",
      "              type {\n",
      "                name: \"pipeline_run\"\n",
      "              }\n",
      "              name {\n",
      "                runtime_parameter {\n",
      "                  name: \"pipeline_run_id\"\n",
      "                  type: STRING\n",
      "                }\n",
      "              }\n",
      "            }\n",
      "            context_queries {\n",
      "              type {\n",
      "                name: \"node\"\n",
      "              }\n",
      "              name {\n",
      "                field_value {\n",
      "                  string_value: \"my_pipeline.Transform\"\n",
      "                }\n",
      "              }\n",
      "            }\n",
      "            artifact_query {\n",
      "              type {\n",
      "                name: \"TransformGraph\"\n",
      "              }\n",
      "            }\n",
      "            output_key: \"transform_graph\"\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "    outputs {\n",
      "      outputs {\n",
      "        key: \"best_hyperparameters\"\n",
      "        value {\n",
      "          artifact_spec {\n",
      "            type {\n",
      "              name: \"HyperParameters\"\n",
      "            }\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "    parameters {\n",
      "      parameters {\n",
      "        key: \"custom_config\"\n",
      "        value {\n",
      "          field_value {\n",
      "            string_value: \"null\"\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "      parameters {\n",
      "        key: \"eval_args\"\n",
      "        value {\n",
      "          field_value {\n",
      "            string_value: \"{\\n  \\\"num_steps\\\": 2\\n}\"\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "      parameters {\n",
      "        key: \"module_path\"\n",
      "        value {\n",
      "          field_value {\n",
      "            string_value: \"bert_aas_utils@gs://tfx-bert-aas-kubeflowpipelines-default/tfx_pipeline_output/my_pipeline/_wheels/tfx_user_code_Tuner-0.0+ae8c7ab9ebdf3b0d138ed4c3226e39b06c47cf35ea403193e9e1be074d7eeb2d-py3-none-any.whl\"\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "      parameters {\n",
      "        key: \"train_args\"\n",
      "        value {\n",
      "          field_value {\n",
      "            string_value: \"{\\n  \\\"num_steps\\\": 5\\n}\"\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "    upstream_nodes: \"Transform\"\n",
      "    execution_options {\n",
      "      caching_options {\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "runtime_spec {\n",
      "  pipeline_root {\n",
      "    runtime_parameter {\n",
      "      name: \"pipeline_root\"\n",
      "      type: STRING\n",
      "      default_value {\n",
      "        string_value: \"gs://tfx-bert-aas-kubeflowpipelines-default/tfx_pipeline_output/my_pipeline\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  pipeline_run_id {\n",
      "    runtime_parameter {\n",
      "      name: \"pipeline_run_id\"\n",
      "      type: STRING\n",
      "    }\n",
      "  }\n",
      "}\n",
      "execution_mode: SYNC\n",
      "deployment_config {\n",
      "  type_url: \"type.googleapis.com/tfx.orchestration.IntermediateDeploymentConfig\"\n",
      "  value: \"\\n\\234\\001\\n\\020ExampleValidator\\022\\207\\001\\nOtype.googleapis.com/tfx.orchestration.executable_spec.PythonClassExecutableSpec\\0224\\n2tfx.components.example_validator.executor.Executor\\n\\204\\001\\n\\005Tuner\\022{\\nOtype.googleapis.com/tfx.orchestration.executable_spec.PythonClassExecutableSpec\\022(\\n&tfx.components.tuner.executor.Executor\\n\\207\\001\\n\\tTransform\\022z\\nHtype.googleapis.com/tfx.orchestration.executable_spec.BeamExecutableSpec\\022.\\n,\\n*tfx.components.transform.executor.Executor\\n\\236\\001\\n\\rCsvExampleGen\\022\\214\\001\\nHtype.googleapis.com/tfx.orchestration.executable_spec.BeamExecutableSpec\\022@\\n>\\n<tfx.components.example_gen.csv_example_gen.executor.Executor\\n\\216\\001\\n\\tSchemaGen\\022\\200\\001\\nOtype.googleapis.com/tfx.orchestration.executable_spec.PythonClassExecutableSpec\\022-\\n+tfx.components.schema_gen.executor.Executor\\n\\220\\001\\n\\rStatisticsGen\\022\\177\\nHtype.googleapis.com/tfx.orchestration.executable_spec.BeamExecutableSpec\\0223\\n1\\n/tfx.components.statistics_gen.executor.Executor\\022\\230\\001\\n\\rCsvExampleGen\\022\\206\\001\\nOtype.googleapis.com/tfx.orchestration.executable_spec.PythonClassExecutableSpec\\0223\\n1tfx.components.example_gen.driver.FileBasedDriver\"\n",
      "}\n",
      "\n",
      "INFO:absl:Adding upstream dependencies for component csvexamplegen\n",
      "INFO:absl:Adding upstream dependencies for component statisticsgen\n",
      "INFO:absl:   ->  Component: csvexamplegen\n",
      "INFO:absl:Adding upstream dependencies for component schemagen\n",
      "INFO:absl:   ->  Component: statisticsgen\n",
      "INFO:absl:Adding upstream dependencies for component examplevalidator\n",
      "INFO:absl:   ->  Component: schemagen\n",
      "INFO:absl:   ->  Component: statisticsgen\n",
      "INFO:absl:Adding upstream dependencies for component transform\n",
      "INFO:absl:   ->  Component: schemagen\n",
      "INFO:absl:   ->  Component: csvexamplegen\n",
      "INFO:absl:Adding upstream dependencies for component tuner\n",
      "INFO:absl:   ->  Component: transform\n",
      "Pipeline \"my_pipeline\" already exists. id=\"3d5e418b-bacb-48ad-9263-433aea5b9bcf\")\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!tfx pipeline create  \\\n",
    "--pipeline-path=kubeflow_runner.py \\\n",
    "--endpoint={ENDPOINT} \\\n",
    "--build-image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QmA6___Y0olh"
   },
   "source": [
    "While creating a pipeline, `Dockerfile` will be generated to build a Docker image. Don't forget to add it to the source control system (for example, git) along with other source files.\n",
    "\n",
    "NOTE: `kubeflow` will be automatically selected as an orchestration engine if `airflow` is not installed and `--engine` is not specified."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wc54hDZu0ole"
   },
   "source": [
    "## Run TFX pipeline\n",
    "\n",
    "Now start an execution run with the newly created pipeline using the `tfx run create` command."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "cKSjVVsa0oli"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:absl:RuntimeParameter is only supported on Cloud-based DAG runner currently.\n",
      "CLI\n",
      "Creating a run for pipeline: my_pipeline\n",
      "Detected Kubeflow.\n",
      "Use --engine flag if you intend to use a different orchestrator.\n",
      "/opt/conda/lib/python3.7/site-packages/kfp/_client.py:182: UserWarning: The host 3ad82eac8d7dd4b7-dot-us-central1.pipelines.googleusercontent.com does not contain the \"http\" or \"https\" protocol. Defaults to \"https\".\n",
      "  ' Defaults to \"https\".' % host)\n",
      "Run created for pipeline: my_pipeline\n",
      "+===============+======================================+========+===========================+=============================================================================================================================+\n",
      "| pipeline_name | run_id                               | status | created_at                | link                                                                                                                        |\n",
      "+===============+======================================+========+===========================+=============================================================================================================================+\n",
      "| my_pipeline   | b0da586a-9f2c-4d43-8d5d-6a236f33f5a3 | None   | 2021-06-04T15:24:37+00:00 | http://3ad82eac8d7dd4b7-dot-us-central1.pipelines.googleusercontent.com/#/runs/details/b0da586a-9f2c-4d43-8d5d-6a236f33f5a3 |\n",
      "+===============+======================================+========+===========================+=============================================================================================================================+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!tfx run create  \\\n",
    "--pipeline-name={PIPELINE_NAME} \\\n",
    "--endpoint={ENDPOINT}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Pg0VxvUC0olk"
   },
   "source": [
    "Or, you can also run the pipeline in the KFP Dashboard.  The new execution run will be listed under Experiments in the KFP Dashboard.  Clicking into the experiment will allow you to monitor progress and visualize the artifacts created during the execution run."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nLN4ges90oll"
   },
   "source": [
    "However, we recommend visiting the KFP Dashboard. You can access the KFP Dashboard from the Cloud AI Platform Pipelines menu in Google Cloud Console. Once you visit the dashboard, you will be able to find the pipeline, and access a wealth of information about the pipeline.\n",
    "For example, you can find your runs under the *Experiments* menu, and when you open your execution run under Experiments you can find all your artifacts from the pipeline under *Artifacts* menu.\n",
    "\n",
    ">Note: If your pipeline run fails, you can see detailed logs for each TFX component in the Experiments tab in the KFP Dashboard.\n",
    "    \n",
    "One of the major sources of failure is permission related problems. Please make sure your KFP cluster has permissions to access Google Cloud APIs. This can be configured [when you create a KFP cluster in GCP](https://cloud.google.com/ai-platform/pipelines/docs/setting-up), or see [Troubleshooting document in GCP](https://cloud.google.com/ai-platform/pipelines/docs/troubleshooting)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bYH8Y2KB0olm"
   },
   "source": [
    "## Step 5. Add components for data validation.\n",
    "\n",
    "In this step, you will add components for data validation including `StatisticsGen`, `SchemaGen`, and `ExampleValidator`. If you are interested in data validation, please see [Get started with Tensorflow Data Validation](https://www.tensorflow.org/tfx/data_validation/get_started).\n",
    "\n",
    ">**Double-click to change directory to `pipeline` and double-click again to open `pipeline.py`**. Find and uncomment the 3 lines which add `StatisticsGen`, `SchemaGen`, and `ExampleValidator` to the pipeline. (Tip: search for comments containing `TODO(step 5):`).  Make sure to save `pipeline.py` after you edit it.\n",
    "\n",
    "You now need to update the existing pipeline with modified pipeline definition. Use the `tfx pipeline update` command to update your pipeline, followed by the `tfx run create` command to create a new execution run of your updated pipeline.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "VE-Pqvto0olm"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:absl:RuntimeParameter is only supported on Cloud-based DAG runner currently.\n",
      "CLI\n",
      "Updating pipeline\n",
      "Detected Kubeflow.\n",
      "Use --engine flag if you intend to use a different orchestrator.\n",
      "/opt/conda/lib/python3.7/site-packages/kfp/_client.py:182: UserWarning: The host 3ad82eac8d7dd4b7-dot-us-central1.pipelines.googleusercontent.com does not contain the \"http\" or \"https\" protocol. Defaults to \"https\".\n",
      "  ' Defaults to \"https\".' % host)\n",
      "INFO:absl:Excluding no splits because exclude_splits is not set.\n",
      "INFO:absl:Excluding no splits because exclude_splits is not set.\n",
      "INFO:absl:Excluding no splits because exclude_splits is not set.\n",
      "INFO:absl:Generating ephemeral wheel package for '/home/jupyter/imported/my_pipeline/pipeline/bert_aas_utils.py' (including modules: ['bert_aas_utils', 'configs', 'pipeline']).\n",
      "INFO:absl:User module package has hash fingerprint version 6796558132309e31778e303a5673f4de4b58135471a6dbc29095acca50bd0590.\n",
      "INFO:absl:Executing: ['/opt/conda/bin/python3.7', '/tmp/tmpcehcxft8/_tfx_generated_setup.py', 'bdist_wheel', '--bdist-dir', '/tmp/tmpatsemeon', '--dist-dir', '/tmp/tmph4hie10a']\n",
      "running bdist_wheel\n",
      "running build\n",
      "running build_py\n",
      "creating build\n",
      "creating build/lib\n",
      "copying bert_aas_utils.py -> build/lib\n",
      "copying configs.py -> build/lib\n",
      "copying pipeline.py -> build/lib\n",
      "installing to /tmp/tmpatsemeon\n",
      "running install\n",
      "running install_lib\n",
      "copying build/lib/configs.py -> /tmp/tmpatsemeon\n",
      "copying build/lib/pipeline.py -> /tmp/tmpatsemeon\n",
      "copying build/lib/bert_aas_utils.py -> /tmp/tmpatsemeon\n",
      "running install_egg_info\n",
      "running egg_info\n",
      "creating tfx_user_code_Transform.egg-info\n",
      "writing tfx_user_code_Transform.egg-info/PKG-INFO\n",
      "writing dependency_links to tfx_user_code_Transform.egg-info/dependency_links.txt\n",
      "writing top-level names to tfx_user_code_Transform.egg-info/top_level.txt\n",
      "writing manifest file 'tfx_user_code_Transform.egg-info/SOURCES.txt'\n",
      "reading manifest file 'tfx_user_code_Transform.egg-info/SOURCES.txt'\n",
      "writing manifest file 'tfx_user_code_Transform.egg-info/SOURCES.txt'\n",
      "Copying tfx_user_code_Transform.egg-info to /tmp/tmpatsemeon/tfx_user_code_Transform-0.0+6796558132309e31778e303a5673f4de4b58135471a6dbc29095acca50bd0590-py3.7.egg-info\n",
      "running install_scripts\n",
      "creating /tmp/tmpatsemeon/tfx_user_code_Transform-0.0+6796558132309e31778e303a5673f4de4b58135471a6dbc29095acca50bd0590.dist-info/WHEEL\n",
      "creating '/tmp/tmph4hie10a/tfx_user_code_Transform-0.0+6796558132309e31778e303a5673f4de4b58135471a6dbc29095acca50bd0590-py3-none-any.whl' and adding '/tmp/tmpatsemeon' to it\n",
      "adding 'bert_aas_utils.py'\n",
      "adding 'configs.py'\n",
      "adding 'pipeline.py'\n",
      "adding 'tfx_user_code_Transform-0.0+6796558132309e31778e303a5673f4de4b58135471a6dbc29095acca50bd0590.dist-info/METADATA'\n",
      "adding 'tfx_user_code_Transform-0.0+6796558132309e31778e303a5673f4de4b58135471a6dbc29095acca50bd0590.dist-info/WHEEL'\n",
      "adding 'tfx_user_code_Transform-0.0+6796558132309e31778e303a5673f4de4b58135471a6dbc29095acca50bd0590.dist-info/top_level.txt'\n",
      "adding 'tfx_user_code_Transform-0.0+6796558132309e31778e303a5673f4de4b58135471a6dbc29095acca50bd0590.dist-info/RECORD'\n",
      "removing /tmp/tmpatsemeon\n",
      "INFO:absl:Successfully built user code wheel distribution at 'gs://tfx-bert-aas-kubeflowpipelines-default/tfx_pipeline_output/my_pipeline/_wheels/tfx_user_code_Transform-0.0+6796558132309e31778e303a5673f4de4b58135471a6dbc29095acca50bd0590-py3-none-any.whl'; target user module is 'bert_aas_utils'.\n",
      "INFO:absl:Full user module path is 'bert_aas_utils@gs://tfx-bert-aas-kubeflowpipelines-default/tfx_pipeline_output/my_pipeline/_wheels/tfx_user_code_Transform-0.0+6796558132309e31778e303a5673f4de4b58135471a6dbc29095acca50bd0590-py3-none-any.whl'\n",
      "INFO:absl:Generating ephemeral wheel package for '/home/jupyter/imported/my_pipeline/pipeline/bert_aas_utils.py' (including modules: ['bert_aas_utils', 'configs', 'pipeline']).\n",
      "INFO:absl:User module package has hash fingerprint version 6796558132309e31778e303a5673f4de4b58135471a6dbc29095acca50bd0590.\n",
      "INFO:absl:Executing: ['/opt/conda/bin/python3.7', '/tmp/tmpsh4ckx0z/_tfx_generated_setup.py', 'bdist_wheel', '--bdist-dir', '/tmp/tmpj5vgwlsh', '--dist-dir', '/tmp/tmpt375lh0j']\n",
      "running bdist_wheel\n",
      "running build\n",
      "running build_py\n",
      "creating build\n",
      "creating build/lib\n",
      "copying bert_aas_utils.py -> build/lib\n",
      "copying configs.py -> build/lib\n",
      "copying pipeline.py -> build/lib\n",
      "installing to /tmp/tmpj5vgwlsh\n",
      "running install\n",
      "running install_lib\n",
      "copying build/lib/configs.py -> /tmp/tmpj5vgwlsh\n",
      "copying build/lib/pipeline.py -> /tmp/tmpj5vgwlsh\n",
      "copying build/lib/bert_aas_utils.py -> /tmp/tmpj5vgwlsh\n",
      "running install_egg_info\n",
      "running egg_info\n",
      "creating tfx_user_code_Trainer.egg-info\n",
      "writing tfx_user_code_Trainer.egg-info/PKG-INFO\n",
      "writing dependency_links to tfx_user_code_Trainer.egg-info/dependency_links.txt\n",
      "writing top-level names to tfx_user_code_Trainer.egg-info/top_level.txt\n",
      "writing manifest file 'tfx_user_code_Trainer.egg-info/SOURCES.txt'\n",
      "reading manifest file 'tfx_user_code_Trainer.egg-info/SOURCES.txt'\n",
      "writing manifest file 'tfx_user_code_Trainer.egg-info/SOURCES.txt'\n",
      "Copying tfx_user_code_Trainer.egg-info to /tmp/tmpj5vgwlsh/tfx_user_code_Trainer-0.0+6796558132309e31778e303a5673f4de4b58135471a6dbc29095acca50bd0590-py3.7.egg-info\n",
      "running install_scripts\n",
      "creating /tmp/tmpj5vgwlsh/tfx_user_code_Trainer-0.0+6796558132309e31778e303a5673f4de4b58135471a6dbc29095acca50bd0590.dist-info/WHEEL\n",
      "creating '/tmp/tmpt375lh0j/tfx_user_code_Trainer-0.0+6796558132309e31778e303a5673f4de4b58135471a6dbc29095acca50bd0590-py3-none-any.whl' and adding '/tmp/tmpj5vgwlsh' to it\n",
      "adding 'bert_aas_utils.py'\n",
      "adding 'configs.py'\n",
      "adding 'pipeline.py'\n",
      "adding 'tfx_user_code_Trainer-0.0+6796558132309e31778e303a5673f4de4b58135471a6dbc29095acca50bd0590.dist-info/METADATA'\n",
      "adding 'tfx_user_code_Trainer-0.0+6796558132309e31778e303a5673f4de4b58135471a6dbc29095acca50bd0590.dist-info/WHEEL'\n",
      "adding 'tfx_user_code_Trainer-0.0+6796558132309e31778e303a5673f4de4b58135471a6dbc29095acca50bd0590.dist-info/top_level.txt'\n",
      "adding 'tfx_user_code_Trainer-0.0+6796558132309e31778e303a5673f4de4b58135471a6dbc29095acca50bd0590.dist-info/RECORD'\n",
      "removing /tmp/tmpj5vgwlsh\n",
      "INFO:absl:Successfully built user code wheel distribution at 'gs://tfx-bert-aas-kubeflowpipelines-default/tfx_pipeline_output/my_pipeline/_wheels/tfx_user_code_Trainer-0.0+6796558132309e31778e303a5673f4de4b58135471a6dbc29095acca50bd0590-py3-none-any.whl'; target user module is 'bert_aas_utils'.\n",
      "INFO:absl:Full user module path is 'bert_aas_utils@gs://tfx-bert-aas-kubeflowpipelines-default/tfx_pipeline_output/my_pipeline/_wheels/tfx_user_code_Trainer-0.0+6796558132309e31778e303a5673f4de4b58135471a6dbc29095acca50bd0590-py3-none-any.whl'\n",
      "INFO:absl:Generated pipeline:\n",
      " pipeline_info {\n",
      "  id: \"my_pipeline\"\n",
      "}\n",
      "nodes {\n",
      "  pipeline_node {\n",
      "    node_info {\n",
      "      type {\n",
      "        name: \"tfx.components.example_gen.csv_example_gen.component.CsvExampleGen\"\n",
      "      }\n",
      "      id: \"CsvExampleGen\"\n",
      "    }\n",
      "    contexts {\n",
      "      contexts {\n",
      "        type {\n",
      "          name: \"pipeline\"\n",
      "        }\n",
      "        name {\n",
      "          field_value {\n",
      "            string_value: \"my_pipeline\"\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "      contexts {\n",
      "        type {\n",
      "          name: \"pipeline_run\"\n",
      "        }\n",
      "        name {\n",
      "          runtime_parameter {\n",
      "            name: \"pipeline_run_id\"\n",
      "            type: STRING\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "      contexts {\n",
      "        type {\n",
      "          name: \"node\"\n",
      "        }\n",
      "        name {\n",
      "          field_value {\n",
      "            string_value: \"my_pipeline.CsvExampleGen\"\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "    outputs {\n",
      "      outputs {\n",
      "        key: \"examples\"\n",
      "        value {\n",
      "          artifact_spec {\n",
      "            type {\n",
      "              name: \"Examples\"\n",
      "              properties {\n",
      "                key: \"span\"\n",
      "                value: INT\n",
      "              }\n",
      "              properties {\n",
      "                key: \"split_names\"\n",
      "                value: STRING\n",
      "              }\n",
      "              properties {\n",
      "                key: \"version\"\n",
      "                value: INT\n",
      "              }\n",
      "            }\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "    parameters {\n",
      "      parameters {\n",
      "        key: \"input_base\"\n",
      "        value {\n",
      "          field_value {\n",
      "            string_value: \"gs://tfx-bert-aas-kubeflowpipelines-default/bert-aas/data/\"\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "      parameters {\n",
      "        key: \"input_config\"\n",
      "        value {\n",
      "          field_value {\n",
      "            string_value: \"{\\n  \\\"splits\\\": [\\n    {\\n      \\\"name\\\": \\\"single_split\\\",\\n      \\\"pattern\\\": \\\"*\\\"\\n    }\\n  ]\\n}\"\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "      parameters {\n",
      "        key: \"output_config\"\n",
      "        value {\n",
      "          field_value {\n",
      "            string_value: \"{\\n  \\\"split_config\\\": {\\n    \\\"splits\\\": [\\n      {\\n        \\\"hash_buckets\\\": 4,\\n        \\\"name\\\": \\\"train\\\"\\n      },\\n      {\\n        \\\"hash_buckets\\\": 1,\\n        \\\"name\\\": \\\"eval\\\"\\n      }\\n    ]\\n  }\\n}\"\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "      parameters {\n",
      "        key: \"output_data_format\"\n",
      "        value {\n",
      "          field_value {\n",
      "            int_value: 6\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "    downstream_nodes: \"StatisticsGen\"\n",
      "    downstream_nodes: \"Transform\"\n",
      "    execution_options {\n",
      "      caching_options {\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "nodes {\n",
      "  pipeline_node {\n",
      "    node_info {\n",
      "      type {\n",
      "        name: \"tfx.components.statistics_gen.component.StatisticsGen\"\n",
      "      }\n",
      "      id: \"StatisticsGen\"\n",
      "    }\n",
      "    contexts {\n",
      "      contexts {\n",
      "        type {\n",
      "          name: \"pipeline\"\n",
      "        }\n",
      "        name {\n",
      "          field_value {\n",
      "            string_value: \"my_pipeline\"\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "      contexts {\n",
      "        type {\n",
      "          name: \"pipeline_run\"\n",
      "        }\n",
      "        name {\n",
      "          runtime_parameter {\n",
      "            name: \"pipeline_run_id\"\n",
      "            type: STRING\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "      contexts {\n",
      "        type {\n",
      "          name: \"node\"\n",
      "        }\n",
      "        name {\n",
      "          field_value {\n",
      "            string_value: \"my_pipeline.StatisticsGen\"\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "    inputs {\n",
      "      inputs {\n",
      "        key: \"examples\"\n",
      "        value {\n",
      "          channels {\n",
      "            producer_node_query {\n",
      "              id: \"CsvExampleGen\"\n",
      "            }\n",
      "            context_queries {\n",
      "              type {\n",
      "                name: \"pipeline\"\n",
      "              }\n",
      "              name {\n",
      "                field_value {\n",
      "                  string_value: \"my_pipeline\"\n",
      "                }\n",
      "              }\n",
      "            }\n",
      "            context_queries {\n",
      "              type {\n",
      "                name: \"pipeline_run\"\n",
      "              }\n",
      "              name {\n",
      "                runtime_parameter {\n",
      "                  name: \"pipeline_run_id\"\n",
      "                  type: STRING\n",
      "                }\n",
      "              }\n",
      "            }\n",
      "            context_queries {\n",
      "              type {\n",
      "                name: \"node\"\n",
      "              }\n",
      "              name {\n",
      "                field_value {\n",
      "                  string_value: \"my_pipeline.CsvExampleGen\"\n",
      "                }\n",
      "              }\n",
      "            }\n",
      "            artifact_query {\n",
      "              type {\n",
      "                name: \"Examples\"\n",
      "              }\n",
      "            }\n",
      "            output_key: \"examples\"\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "    outputs {\n",
      "      outputs {\n",
      "        key: \"statistics\"\n",
      "        value {\n",
      "          artifact_spec {\n",
      "            type {\n",
      "              name: \"ExampleStatistics\"\n",
      "              properties {\n",
      "                key: \"span\"\n",
      "                value: INT\n",
      "              }\n",
      "              properties {\n",
      "                key: \"split_names\"\n",
      "                value: STRING\n",
      "              }\n",
      "            }\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "    parameters {\n",
      "      parameters {\n",
      "        key: \"exclude_splits\"\n",
      "        value {\n",
      "          field_value {\n",
      "            string_value: \"[]\"\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "    upstream_nodes: \"CsvExampleGen\"\n",
      "    downstream_nodes: \"ExampleValidator\"\n",
      "    downstream_nodes: \"SchemaGen\"\n",
      "    execution_options {\n",
      "      caching_options {\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "nodes {\n",
      "  pipeline_node {\n",
      "    node_info {\n",
      "      type {\n",
      "        name: \"tfx.components.schema_gen.component.SchemaGen\"\n",
      "      }\n",
      "      id: \"SchemaGen\"\n",
      "    }\n",
      "    contexts {\n",
      "      contexts {\n",
      "        type {\n",
      "          name: \"pipeline\"\n",
      "        }\n",
      "        name {\n",
      "          field_value {\n",
      "            string_value: \"my_pipeline\"\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "      contexts {\n",
      "        type {\n",
      "          name: \"pipeline_run\"\n",
      "        }\n",
      "        name {\n",
      "          runtime_parameter {\n",
      "            name: \"pipeline_run_id\"\n",
      "            type: STRING\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "      contexts {\n",
      "        type {\n",
      "          name: \"node\"\n",
      "        }\n",
      "        name {\n",
      "          field_value {\n",
      "            string_value: \"my_pipeline.SchemaGen\"\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "    inputs {\n",
      "      inputs {\n",
      "        key: \"statistics\"\n",
      "        value {\n",
      "          channels {\n",
      "            producer_node_query {\n",
      "              id: \"StatisticsGen\"\n",
      "            }\n",
      "            context_queries {\n",
      "              type {\n",
      "                name: \"pipeline\"\n",
      "              }\n",
      "              name {\n",
      "                field_value {\n",
      "                  string_value: \"my_pipeline\"\n",
      "                }\n",
      "              }\n",
      "            }\n",
      "            context_queries {\n",
      "              type {\n",
      "                name: \"pipeline_run\"\n",
      "              }\n",
      "              name {\n",
      "                runtime_parameter {\n",
      "                  name: \"pipeline_run_id\"\n",
      "                  type: STRING\n",
      "                }\n",
      "              }\n",
      "            }\n",
      "            context_queries {\n",
      "              type {\n",
      "                name: \"node\"\n",
      "              }\n",
      "              name {\n",
      "                field_value {\n",
      "                  string_value: \"my_pipeline.StatisticsGen\"\n",
      "                }\n",
      "              }\n",
      "            }\n",
      "            artifact_query {\n",
      "              type {\n",
      "                name: \"ExampleStatistics\"\n",
      "              }\n",
      "            }\n",
      "            output_key: \"statistics\"\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "    outputs {\n",
      "      outputs {\n",
      "        key: \"schema\"\n",
      "        value {\n",
      "          artifact_spec {\n",
      "            type {\n",
      "              name: \"Schema\"\n",
      "            }\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "    parameters {\n",
      "      parameters {\n",
      "        key: \"exclude_splits\"\n",
      "        value {\n",
      "          field_value {\n",
      "            string_value: \"[]\"\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "      parameters {\n",
      "        key: \"infer_feature_shape\"\n",
      "        value {\n",
      "          field_value {\n",
      "            int_value: 1\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "    upstream_nodes: \"StatisticsGen\"\n",
      "    downstream_nodes: \"ExampleValidator\"\n",
      "    downstream_nodes: \"Trainer\"\n",
      "    downstream_nodes: \"Transform\"\n",
      "    execution_options {\n",
      "      caching_options {\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "nodes {\n",
      "  pipeline_node {\n",
      "    node_info {\n",
      "      type {\n",
      "        name: \"tfx.components.example_validator.component.ExampleValidator\"\n",
      "      }\n",
      "      id: \"ExampleValidator\"\n",
      "    }\n",
      "    contexts {\n",
      "      contexts {\n",
      "        type {\n",
      "          name: \"pipeline\"\n",
      "        }\n",
      "        name {\n",
      "          field_value {\n",
      "            string_value: \"my_pipeline\"\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "      contexts {\n",
      "        type {\n",
      "          name: \"pipeline_run\"\n",
      "        }\n",
      "        name {\n",
      "          runtime_parameter {\n",
      "            name: \"pipeline_run_id\"\n",
      "            type: STRING\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "      contexts {\n",
      "        type {\n",
      "          name: \"node\"\n",
      "        }\n",
      "        name {\n",
      "          field_value {\n",
      "            string_value: \"my_pipeline.ExampleValidator\"\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "    inputs {\n",
      "      inputs {\n",
      "        key: \"schema\"\n",
      "        value {\n",
      "          channels {\n",
      "            producer_node_query {\n",
      "              id: \"SchemaGen\"\n",
      "            }\n",
      "            context_queries {\n",
      "              type {\n",
      "                name: \"pipeline\"\n",
      "              }\n",
      "              name {\n",
      "                field_value {\n",
      "                  string_value: \"my_pipeline\"\n",
      "                }\n",
      "              }\n",
      "            }\n",
      "            context_queries {\n",
      "              type {\n",
      "                name: \"pipeline_run\"\n",
      "              }\n",
      "              name {\n",
      "                runtime_parameter {\n",
      "                  name: \"pipeline_run_id\"\n",
      "                  type: STRING\n",
      "                }\n",
      "              }\n",
      "            }\n",
      "            context_queries {\n",
      "              type {\n",
      "                name: \"node\"\n",
      "              }\n",
      "              name {\n",
      "                field_value {\n",
      "                  string_value: \"my_pipeline.SchemaGen\"\n",
      "                }\n",
      "              }\n",
      "            }\n",
      "            artifact_query {\n",
      "              type {\n",
      "                name: \"Schema\"\n",
      "              }\n",
      "            }\n",
      "            output_key: \"schema\"\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "      inputs {\n",
      "        key: \"statistics\"\n",
      "        value {\n",
      "          channels {\n",
      "            producer_node_query {\n",
      "              id: \"StatisticsGen\"\n",
      "            }\n",
      "            context_queries {\n",
      "              type {\n",
      "                name: \"pipeline\"\n",
      "              }\n",
      "              name {\n",
      "                field_value {\n",
      "                  string_value: \"my_pipeline\"\n",
      "                }\n",
      "              }\n",
      "            }\n",
      "            context_queries {\n",
      "              type {\n",
      "                name: \"pipeline_run\"\n",
      "              }\n",
      "              name {\n",
      "                runtime_parameter {\n",
      "                  name: \"pipeline_run_id\"\n",
      "                  type: STRING\n",
      "                }\n",
      "              }\n",
      "            }\n",
      "            context_queries {\n",
      "              type {\n",
      "                name: \"node\"\n",
      "              }\n",
      "              name {\n",
      "                field_value {\n",
      "                  string_value: \"my_pipeline.StatisticsGen\"\n",
      "                }\n",
      "              }\n",
      "            }\n",
      "            artifact_query {\n",
      "              type {\n",
      "                name: \"ExampleStatistics\"\n",
      "              }\n",
      "            }\n",
      "            output_key: \"statistics\"\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "    outputs {\n",
      "      outputs {\n",
      "        key: \"anomalies\"\n",
      "        value {\n",
      "          artifact_spec {\n",
      "            type {\n",
      "              name: \"ExampleAnomalies\"\n",
      "              properties {\n",
      "                key: \"span\"\n",
      "                value: INT\n",
      "              }\n",
      "              properties {\n",
      "                key: \"split_names\"\n",
      "                value: STRING\n",
      "              }\n",
      "            }\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "    parameters {\n",
      "      parameters {\n",
      "        key: \"exclude_splits\"\n",
      "        value {\n",
      "          field_value {\n",
      "            string_value: \"[]\"\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "    upstream_nodes: \"SchemaGen\"\n",
      "    upstream_nodes: \"StatisticsGen\"\n",
      "    execution_options {\n",
      "      caching_options {\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "nodes {\n",
      "  pipeline_node {\n",
      "    node_info {\n",
      "      type {\n",
      "        name: \"tfx.components.transform.component.Transform\"\n",
      "      }\n",
      "      id: \"Transform\"\n",
      "    }\n",
      "    contexts {\n",
      "      contexts {\n",
      "        type {\n",
      "          name: \"pipeline\"\n",
      "        }\n",
      "        name {\n",
      "          field_value {\n",
      "            string_value: \"my_pipeline\"\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "      contexts {\n",
      "        type {\n",
      "          name: \"pipeline_run\"\n",
      "        }\n",
      "        name {\n",
      "          runtime_parameter {\n",
      "            name: \"pipeline_run_id\"\n",
      "            type: STRING\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "      contexts {\n",
      "        type {\n",
      "          name: \"node\"\n",
      "        }\n",
      "        name {\n",
      "          field_value {\n",
      "            string_value: \"my_pipeline.Transform\"\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "    inputs {\n",
      "      inputs {\n",
      "        key: \"examples\"\n",
      "        value {\n",
      "          channels {\n",
      "            producer_node_query {\n",
      "              id: \"CsvExampleGen\"\n",
      "            }\n",
      "            context_queries {\n",
      "              type {\n",
      "                name: \"pipeline\"\n",
      "              }\n",
      "              name {\n",
      "                field_value {\n",
      "                  string_value: \"my_pipeline\"\n",
      "                }\n",
      "              }\n",
      "            }\n",
      "            context_queries {\n",
      "              type {\n",
      "                name: \"pipeline_run\"\n",
      "              }\n",
      "              name {\n",
      "                runtime_parameter {\n",
      "                  name: \"pipeline_run_id\"\n",
      "                  type: STRING\n",
      "                }\n",
      "              }\n",
      "            }\n",
      "            context_queries {\n",
      "              type {\n",
      "                name: \"node\"\n",
      "              }\n",
      "              name {\n",
      "                field_value {\n",
      "                  string_value: \"my_pipeline.CsvExampleGen\"\n",
      "                }\n",
      "              }\n",
      "            }\n",
      "            artifact_query {\n",
      "              type {\n",
      "                name: \"Examples\"\n",
      "              }\n",
      "            }\n",
      "            output_key: \"examples\"\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "      inputs {\n",
      "        key: \"schema\"\n",
      "        value {\n",
      "          channels {\n",
      "            producer_node_query {\n",
      "              id: \"SchemaGen\"\n",
      "            }\n",
      "            context_queries {\n",
      "              type {\n",
      "                name: \"pipeline\"\n",
      "              }\n",
      "              name {\n",
      "                field_value {\n",
      "                  string_value: \"my_pipeline\"\n",
      "                }\n",
      "              }\n",
      "            }\n",
      "            context_queries {\n",
      "              type {\n",
      "                name: \"pipeline_run\"\n",
      "              }\n",
      "              name {\n",
      "                runtime_parameter {\n",
      "                  name: \"pipeline_run_id\"\n",
      "                  type: STRING\n",
      "                }\n",
      "              }\n",
      "            }\n",
      "            context_queries {\n",
      "              type {\n",
      "                name: \"node\"\n",
      "              }\n",
      "              name {\n",
      "                field_value {\n",
      "                  string_value: \"my_pipeline.SchemaGen\"\n",
      "                }\n",
      "              }\n",
      "            }\n",
      "            artifact_query {\n",
      "              type {\n",
      "                name: \"Schema\"\n",
      "              }\n",
      "            }\n",
      "            output_key: \"schema\"\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "    outputs {\n",
      "      outputs {\n",
      "        key: \"post_transform_anomalies\"\n",
      "        value {\n",
      "          artifact_spec {\n",
      "            type {\n",
      "              name: \"ExampleAnomalies\"\n",
      "              properties {\n",
      "                key: \"span\"\n",
      "                value: INT\n",
      "              }\n",
      "              properties {\n",
      "                key: \"split_names\"\n",
      "                value: STRING\n",
      "              }\n",
      "            }\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "      outputs {\n",
      "        key: \"post_transform_schema\"\n",
      "        value {\n",
      "          artifact_spec {\n",
      "            type {\n",
      "              name: \"Schema\"\n",
      "            }\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "      outputs {\n",
      "        key: \"post_transform_stats\"\n",
      "        value {\n",
      "          artifact_spec {\n",
      "            type {\n",
      "              name: \"ExampleStatistics\"\n",
      "              properties {\n",
      "                key: \"span\"\n",
      "                value: INT\n",
      "              }\n",
      "              properties {\n",
      "                key: \"split_names\"\n",
      "                value: STRING\n",
      "              }\n",
      "            }\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "      outputs {\n",
      "        key: \"pre_transform_schema\"\n",
      "        value {\n",
      "          artifact_spec {\n",
      "            type {\n",
      "              name: \"Schema\"\n",
      "            }\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "      outputs {\n",
      "        key: \"pre_transform_stats\"\n",
      "        value {\n",
      "          artifact_spec {\n",
      "            type {\n",
      "              name: \"ExampleStatistics\"\n",
      "              properties {\n",
      "                key: \"span\"\n",
      "                value: INT\n",
      "              }\n",
      "              properties {\n",
      "                key: \"split_names\"\n",
      "                value: STRING\n",
      "              }\n",
      "            }\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "      outputs {\n",
      "        key: \"transform_graph\"\n",
      "        value {\n",
      "          artifact_spec {\n",
      "            type {\n",
      "              name: \"TransformGraph\"\n",
      "            }\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "      outputs {\n",
      "        key: \"transformed_examples\"\n",
      "        value {\n",
      "          artifact_spec {\n",
      "            type {\n",
      "              name: \"Examples\"\n",
      "              properties {\n",
      "                key: \"span\"\n",
      "                value: INT\n",
      "              }\n",
      "              properties {\n",
      "                key: \"split_names\"\n",
      "                value: STRING\n",
      "              }\n",
      "              properties {\n",
      "                key: \"version\"\n",
      "                value: INT\n",
      "              }\n",
      "            }\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "      outputs {\n",
      "        key: \"updated_analyzer_cache\"\n",
      "        value {\n",
      "          artifact_spec {\n",
      "            type {\n",
      "              name: \"TransformCache\"\n",
      "            }\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "    parameters {\n",
      "      parameters {\n",
      "        key: \"custom_config\"\n",
      "        value {\n",
      "          field_value {\n",
      "            string_value: \"null\"\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "      parameters {\n",
      "        key: \"disable_statistics\"\n",
      "        value {\n",
      "          field_value {\n",
      "            int_value: 0\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "      parameters {\n",
      "        key: \"force_tf_compat_v1\"\n",
      "        value {\n",
      "          field_value {\n",
      "            int_value: 0\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "      parameters {\n",
      "        key: \"module_path\"\n",
      "        value {\n",
      "          field_value {\n",
      "            string_value: \"bert_aas_utils@gs://tfx-bert-aas-kubeflowpipelines-default/tfx_pipeline_output/my_pipeline/_wheels/tfx_user_code_Transform-0.0+6796558132309e31778e303a5673f4de4b58135471a6dbc29095acca50bd0590-py3-none-any.whl\"\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "    upstream_nodes: \"CsvExampleGen\"\n",
      "    upstream_nodes: \"SchemaGen\"\n",
      "    downstream_nodes: \"Trainer\"\n",
      "    execution_options {\n",
      "      caching_options {\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "nodes {\n",
      "  pipeline_node {\n",
      "    node_info {\n",
      "      type {\n",
      "        name: \"tfx.components.trainer.component.Trainer\"\n",
      "      }\n",
      "      id: \"Trainer\"\n",
      "    }\n",
      "    contexts {\n",
      "      contexts {\n",
      "        type {\n",
      "          name: \"pipeline\"\n",
      "        }\n",
      "        name {\n",
      "          field_value {\n",
      "            string_value: \"my_pipeline\"\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "      contexts {\n",
      "        type {\n",
      "          name: \"pipeline_run\"\n",
      "        }\n",
      "        name {\n",
      "          runtime_parameter {\n",
      "            name: \"pipeline_run_id\"\n",
      "            type: STRING\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "      contexts {\n",
      "        type {\n",
      "          name: \"node\"\n",
      "        }\n",
      "        name {\n",
      "          field_value {\n",
      "            string_value: \"my_pipeline.Trainer\"\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "    inputs {\n",
      "      inputs {\n",
      "        key: \"examples\"\n",
      "        value {\n",
      "          channels {\n",
      "            producer_node_query {\n",
      "              id: \"Transform\"\n",
      "            }\n",
      "            context_queries {\n",
      "              type {\n",
      "                name: \"pipeline\"\n",
      "              }\n",
      "              name {\n",
      "                field_value {\n",
      "                  string_value: \"my_pipeline\"\n",
      "                }\n",
      "              }\n",
      "            }\n",
      "            context_queries {\n",
      "              type {\n",
      "                name: \"pipeline_run\"\n",
      "              }\n",
      "              name {\n",
      "                runtime_parameter {\n",
      "                  name: \"pipeline_run_id\"\n",
      "                  type: STRING\n",
      "                }\n",
      "              }\n",
      "            }\n",
      "            context_queries {\n",
      "              type {\n",
      "                name: \"node\"\n",
      "              }\n",
      "              name {\n",
      "                field_value {\n",
      "                  string_value: \"my_pipeline.Transform\"\n",
      "                }\n",
      "              }\n",
      "            }\n",
      "            artifact_query {\n",
      "              type {\n",
      "                name: \"Examples\"\n",
      "              }\n",
      "            }\n",
      "            output_key: \"transformed_examples\"\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "      inputs {\n",
      "        key: \"schema\"\n",
      "        value {\n",
      "          channels {\n",
      "            producer_node_query {\n",
      "              id: \"SchemaGen\"\n",
      "            }\n",
      "            context_queries {\n",
      "              type {\n",
      "                name: \"pipeline\"\n",
      "              }\n",
      "              name {\n",
      "                field_value {\n",
      "                  string_value: \"my_pipeline\"\n",
      "                }\n",
      "              }\n",
      "            }\n",
      "            context_queries {\n",
      "              type {\n",
      "                name: \"pipeline_run\"\n",
      "              }\n",
      "              name {\n",
      "                runtime_parameter {\n",
      "                  name: \"pipeline_run_id\"\n",
      "                  type: STRING\n",
      "                }\n",
      "              }\n",
      "            }\n",
      "            context_queries {\n",
      "              type {\n",
      "                name: \"node\"\n",
      "              }\n",
      "              name {\n",
      "                field_value {\n",
      "                  string_value: \"my_pipeline.SchemaGen\"\n",
      "                }\n",
      "              }\n",
      "            }\n",
      "            artifact_query {\n",
      "              type {\n",
      "                name: \"Schema\"\n",
      "              }\n",
      "            }\n",
      "            output_key: \"schema\"\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "      inputs {\n",
      "        key: \"transform_graph\"\n",
      "        value {\n",
      "          channels {\n",
      "            producer_node_query {\n",
      "              id: \"Transform\"\n",
      "            }\n",
      "            context_queries {\n",
      "              type {\n",
      "                name: \"pipeline\"\n",
      "              }\n",
      "              name {\n",
      "                field_value {\n",
      "                  string_value: \"my_pipeline\"\n",
      "                }\n",
      "              }\n",
      "            }\n",
      "            context_queries {\n",
      "              type {\n",
      "                name: \"pipeline_run\"\n",
      "              }\n",
      "              name {\n",
      "                runtime_parameter {\n",
      "                  name: \"pipeline_run_id\"\n",
      "                  type: STRING\n",
      "                }\n",
      "              }\n",
      "            }\n",
      "            context_queries {\n",
      "              type {\n",
      "                name: \"node\"\n",
      "              }\n",
      "              name {\n",
      "                field_value {\n",
      "                  string_value: \"my_pipeline.Transform\"\n",
      "                }\n",
      "              }\n",
      "            }\n",
      "            artifact_query {\n",
      "              type {\n",
      "                name: \"TransformGraph\"\n",
      "              }\n",
      "            }\n",
      "            output_key: \"transform_graph\"\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "    outputs {\n",
      "      outputs {\n",
      "        key: \"model\"\n",
      "        value {\n",
      "          artifact_spec {\n",
      "            type {\n",
      "              name: \"Model\"\n",
      "            }\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "      outputs {\n",
      "        key: \"model_run\"\n",
      "        value {\n",
      "          artifact_spec {\n",
      "            type {\n",
      "              name: \"ModelRun\"\n",
      "            }\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "    parameters {\n",
      "      parameters {\n",
      "        key: \"custom_config\"\n",
      "        value {\n",
      "          field_value {\n",
      "            string_value: \"null\"\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "      parameters {\n",
      "        key: \"eval_args\"\n",
      "        value {\n",
      "          field_value {\n",
      "            string_value: \"{\\n  \\\"num_steps\\\": 5\\n}\"\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "      parameters {\n",
      "        key: \"module_path\"\n",
      "        value {\n",
      "          field_value {\n",
      "            string_value: \"bert_aas_utils@gs://tfx-bert-aas-kubeflowpipelines-default/tfx_pipeline_output/my_pipeline/_wheels/tfx_user_code_Trainer-0.0+6796558132309e31778e303a5673f4de4b58135471a6dbc29095acca50bd0590-py3-none-any.whl\"\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "      parameters {\n",
      "        key: \"train_args\"\n",
      "        value {\n",
      "          field_value {\n",
      "            string_value: \"{\\n  \\\"num_steps\\\": 20\\n}\"\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "    upstream_nodes: \"SchemaGen\"\n",
      "    upstream_nodes: \"Transform\"\n",
      "    execution_options {\n",
      "      caching_options {\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "runtime_spec {\n",
      "  pipeline_root {\n",
      "    runtime_parameter {\n",
      "      name: \"pipeline_root\"\n",
      "      type: STRING\n",
      "      default_value {\n",
      "        string_value: \"gs://tfx-bert-aas-kubeflowpipelines-default/tfx_pipeline_output/my_pipeline\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  pipeline_run_id {\n",
      "    runtime_parameter {\n",
      "      name: \"pipeline_run_id\"\n",
      "      type: STRING\n",
      "    }\n",
      "  }\n",
      "}\n",
      "execution_mode: SYNC\n",
      "deployment_config {\n",
      "  type_url: \"type.googleapis.com/tfx.orchestration.IntermediateDeploymentConfig\"\n",
      "  value: \"\\n\\236\\001\\n\\rCsvExampleGen\\022\\214\\001\\nHtype.googleapis.com/tfx.orchestration.executable_spec.BeamExecutableSpec\\022@\\n>\\n<tfx.components.example_gen.csv_example_gen.executor.Executor\\n\\220\\001\\n\\rStatisticsGen\\022\\177\\nHtype.googleapis.com/tfx.orchestration.executable_spec.BeamExecutableSpec\\0223\\n1\\n/tfx.components.statistics_gen.executor.Executor\\n\\220\\001\\n\\007Trainer\\022\\204\\001\\nOtype.googleapis.com/tfx.orchestration.executable_spec.PythonClassExecutableSpec\\0221\\n/tfx.components.trainer.executor.GenericExecutor\\n\\207\\001\\n\\tTransform\\022z\\nHtype.googleapis.com/tfx.orchestration.executable_spec.BeamExecutableSpec\\022.\\n,\\n*tfx.components.transform.executor.Executor\\n\\216\\001\\n\\tSchemaGen\\022\\200\\001\\nOtype.googleapis.com/tfx.orchestration.executable_spec.PythonClassExecutableSpec\\022-\\n+tfx.components.schema_gen.executor.Executor\\n\\234\\001\\n\\020ExampleValidator\\022\\207\\001\\nOtype.googleapis.com/tfx.orchestration.executable_spec.PythonClassExecutableSpec\\0224\\n2tfx.components.example_validator.executor.Executor\\022\\230\\001\\n\\rCsvExampleGen\\022\\206\\001\\nOtype.googleapis.com/tfx.orchestration.executable_spec.PythonClassExecutableSpec\\0223\\n1tfx.components.example_gen.driver.FileBasedDriver\"\n",
      "}\n",
      "\n",
      "INFO:absl:Adding upstream dependencies for component csvexamplegen\n",
      "INFO:absl:Adding upstream dependencies for component statisticsgen\n",
      "INFO:absl:   ->  Component: csvexamplegen\n",
      "INFO:absl:Adding upstream dependencies for component schemagen\n",
      "INFO:absl:   ->  Component: statisticsgen\n",
      "INFO:absl:Adding upstream dependencies for component examplevalidator\n",
      "INFO:absl:   ->  Component: schemagen\n",
      "INFO:absl:   ->  Component: statisticsgen\n",
      "INFO:absl:Adding upstream dependencies for component transform\n",
      "INFO:absl:   ->  Component: schemagen\n",
      "INFO:absl:   ->  Component: csvexamplegen\n",
      "INFO:absl:Adding upstream dependencies for component trainer\n",
      "INFO:absl:   ->  Component: transform\n",
      "INFO:absl:   ->  Component: schemagen\n",
      "Please access the pipeline detail page at http://3ad82eac8d7dd4b7-dot-us-central1.pipelines.googleusercontent.com/#/pipelines/details/3d5e418b-bacb-48ad-9263-433aea5b9bcf\n",
      "Pipeline \"my_pipeline\" updated successfully.\n",
      "\u001b[0mWARNING:absl:RuntimeParameter is only supported on Cloud-based DAG runner currently.\n",
      "CLI\n",
      "Creating a run for pipeline: my_pipeline\n",
      "Detected Kubeflow.\n",
      "Use --engine flag if you intend to use a different orchestrator.\n",
      "/opt/conda/lib/python3.7/site-packages/kfp/_client.py:182: UserWarning: The host 3ad82eac8d7dd4b7-dot-us-central1.pipelines.googleusercontent.com does not contain the \"http\" or \"https\" protocol. Defaults to \"https\".\n",
      "  ' Defaults to \"https\".' % host)\n",
      "Run created for pipeline: my_pipeline\n",
      "+===============+======================================+========+===========================+=============================================================================================================================+\n",
      "| pipeline_name | run_id                               | status | created_at                | link                                                                                                                        |\n",
      "+===============+======================================+========+===========================+=============================================================================================================================+\n",
      "| my_pipeline   | 7b87e5fe-235a-48a4-ab4a-309d5a486e14 | None   | 2021-06-04T16:25:07+00:00 | http://3ad82eac8d7dd4b7-dot-us-central1.pipelines.googleusercontent.com/#/runs/details/7b87e5fe-235a-48a4-ab4a-309d5a486e14 |\n",
      "+===============+======================================+========+===========================+=============================================================================================================================+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Update the pipeline\n",
    "!tfx pipeline update \\\n",
    "--pipeline-path=kubeflow_runner.py \\\n",
    "--endpoint={ENDPOINT}\n",
    "# You can run the pipeline the same way.\n",
    "!tfx run create --pipeline-name {PIPELINE_NAME} --endpoint={ENDPOINT}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8q1ZYEHX0olo"
   },
   "source": [
    "### Check pipeline outputs\n",
    "\n",
    "Visit the KFP dashboard to find pipeline outputs in the page for your pipeline run. Click the *Experiments* tab on the left, and *All runs* in the Experiments page. You should be able to find the latest run under the name of your pipeline."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ksWfVQUnMYCX"
   },
   "source": [
    "When this execution run finishes successfully, you have now created and run your first TFX pipeline in AI Platform Pipelines!\n",
    "\n",
    "**NOTE:** If we changed anything in the model code, we have to rebuild the\n",
    "container image, too. We can trigger rebuild using `--build-image` flag in the\n",
    "`pipeline update` command.\n",
    "\n",
    "**NOTE:** You might have noticed that every time we create a pipeline run, every component runs again and again even though the input and the parameters were not changed.\n",
    "It is waste of time and resources, and you can skip those executions with pipeline caching. You can enable caching by specifying `enable_cache=True` for the `Pipeline` object in `pipeline.py`.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kJOmh1RY0olz"
   },
   "source": [
    "## Step 9. (*Optional*) Try Cloud AI Platform Training and Prediction with KFP\n",
    "\n",
    "TFX interoperates with several managed GCP services, such as [Cloud AI Platform for Training and Prediction](https://cloud.google.com/ai-platform/). You can set your `Trainer` component to use Cloud AI Platform Training, a managed service for training ML models. Moreover, when your model is built and ready to be served, you can *push* your model to Cloud AI Platform Prediction for serving. In this step, we will set our `Trainer` and `Pusher` component to use Cloud AI Platform services.\n",
    "\n",
    ">Before editing files, you might first have to enable *AI Platform Training & Prediction API*.\n",
    "\n",
    ">**Double-click `pipeline` to change directory, and double-click to open `configs.py`**. Uncomment the definition of `GOOGLE_CLOUD_REGION`, `GCP_AI_PLATFORM_TRAINING_ARGS` and `GCP_AI_PLATFORM_SERVING_ARGS`. We will use our custom built container image to train a model in Cloud AI Platform Training, so we should set `masterConfig.imageUri` in `GCP_AI_PLATFORM_TRAINING_ARGS` to the same value as `CUSTOM_TFX_IMAGE` above.\n",
    "\n",
    ">**Change directory one level up, and double-click to open `kubeflow_runner.py`**. Uncomment `ai_platform_training_args` and `ai_platform_serving_args`.\n",
    "\n",
    "Update the pipeline and create an execution run as we did in step 5 and 6."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "yxOjhBmG0ol0"
   },
   "outputs": [],
   "source": [
    "!tfx pipeline update \\\n",
    "--pipeline-path=kubeflow_runner.py \\\n",
    "--endpoint={ENDPOINT}\n",
    "!tfx run create --pipeline-name {PIPELINE_NAME} --endpoint={ENDPOINT}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BkoIMUfj0ol2"
   },
   "source": [
    "You can find your training jobs in [Cloud AI Platform Jobs](https://console.cloud.google.com/ai-platform/jobs). If your pipeline completed successfully, you can find your model in [Cloud AI Platform Models](https://console.cloud.google.com/ai-platform/models)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4DRTFdTy0ol3"
   },
   "source": [
    "## Step 10. Ingest YOUR data to the pipeline\n",
    "\n",
    "We made a pipeline for a model using the Chicago Taxi dataset. Now it's time to put your data into the pipeline.\n",
    "\n",
    "Your data can be stored anywhere your pipeline can access, including GCS, or BigQuery. You will need to modify the pipeline definition to access your data.\n",
    "\n",
    "1. If your data is stored in files, modify the `DATA_PATH` in `kubeflow_runner.py` or `local_runner.py` and set it to the location of your files. If your data is stored in BigQuery, modify `BIG_QUERY_QUERY` in `pipeline/configs.py` to correctly query for your data.\n",
    "1. Add features in `models/features.py`.\n",
    "1. Modify `models/preprocessing.py` to [transform input data for training](https://www.tensorflow.org/tfx/guide/transform).\n",
    "1. Modify `models/keras/model.py` and `models/keras/constants.py` to [describe your ML model](https://www.tensorflow.org/tfx/guide/trainer).\n",
    "  - You can use an estimator based model, too. Change `RUN_FN` constant to `models.estimator.model.run_fn` in `pipeline/configs.py`.\n",
    "\n",
    "Please see [Trainer component guide](https://www.tensorflow.org/tfx/guide/trainer) for more introduction."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "20KRGsPX0ol3"
   },
   "source": [
    "## Cleaning up\n",
    "\n",
    "To clean up all Google Cloud resources used in this project, you can [delete the Google Cloud project](https://cloud.google.com/resource-manager/docs/creating-managing-projects#shutting_down_projects) you used for the tutorial.\n",
    "\n",
    "Alternatively, you can clean up individual resources by visiting each consoles:\n",
    "- [Google Cloud Storage](https://console.cloud.google.com/storage)\n",
    "- [Google Container Registry](https://console.cloud.google.com/gcr)\n",
    "- [Google Kubernetes Engine](https://console.cloud.google.com/kubernetes)\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "template.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "environment": {
   "name": "tf2-gpu.2-5.m71",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/tf2-gpu.2-5:m71"
  },
  "kernelspec": {
   "display_name": "Python [conda env:root] *",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
